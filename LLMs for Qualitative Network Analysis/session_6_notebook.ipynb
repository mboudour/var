{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">Â© 2026 Moses Boudourides. All Rights Reserved.</div>\n",
    "\n",
    "# LLMs for Qualitative and Mixed-Methods Social Network Analysis (SNA)\n",
    "## Moses Boudourides\n",
    "\n",
    "# Session 6: Transition to Practice and Research Agendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import hashlib\n",
    "import random\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import IPython\n",
    "from openai import OpenAI\n",
    "# import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. & 2. KEY LOADING & INITIALIZATION ---\n",
    "\n",
    "# Force Google to use REST to avoid ALTS/GCP credential errors\n",
    "os.environ[\"GOOGLE_API_USE_MTLS\"] = \"never\" \n",
    "\n",
    "def get_api_key(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return f.read().strip().replace('\"', '').replace(\"'\", \"\")\n",
    "    return None\n",
    "\n",
    "oa_key = get_api_key(\"openai_key.txt\")\n",
    "# gem_key = get_api_key(\"gemini_key.txt\")\n",
    "\n",
    "# Initialize OpenAI\n",
    "client_oa = OpenAI(api_key=oa_key)\n",
    "\n",
    "# # Initialize Gemini using 'rest' transport to bypass gRPC/ALTS errors\n",
    "# genai.configure(api_key=gem_key, transport='rest')\n",
    "\n",
    "# # Dynamic Model Selection\n",
    "# available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
    "# target_model = 'gemini-1.5-flash' if 'models/gemini-1.5-flash' in available_models else available_models[0].split('/')[-1]\n",
    "# model_gemini = genai.GenerativeModel(target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Transition to Practice and Research Agendas\n",
    "\n",
    "**Goal:**  \n",
    "Provide reusable templates and conceptual scaffolding for independent research using LLM-augmented qualitative SNA.\n",
    "\n",
    "**Important Note:** This notebook is a **template**, not a pipeline. It is designed to be adapted, critiqued, and extended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. DATA & PERSISTENT QUERY STEP ---\n",
    "\n",
    "# 2. Persistence Logic\n",
    "CACHE_FILE = \"llm_cache_s6.json\"\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"r\") as f:\n",
    "        cache = json.load(f)\n",
    "else:\n",
    "    cache = {}\n",
    "\n",
    "def get_label(model_id, text, api_func, prompt_type=\"practice\"):\n",
    "    # Unique key ensures cache stays valid even if prompt or text changes\n",
    "    cache_key = f\"{model_id}_{prompt_type}_{text[:50]}\"\n",
    "    \n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    # Cache Miss: Call API\n",
    "    result = api_func(text)\n",
    "    cache[cache_key] = result\n",
    "    \n",
    "    # Save updated cache to disk\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump(cache, f)\n",
    "    return result\n",
    "\n",
    "# 3. API Execution Wrappers\n",
    "def query_openai_extraction(text):\n",
    "    prompt = f\"\"\"Extract relationships and their meanings from this text.\n",
    "Identify the type of relationship (e.g., rivalry, mentorship, collaboration).\n",
    "\n",
    "Text: {text}\"\"\"\n",
    "    res = client_oa.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return res.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Design Checklist\n",
    "\n",
    "Before using LLMs in your research, clarify these essential elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESEARCH DESIGN CHECKLIST:\n",
      "============================================================\n",
      "\n",
      "QUESTION:\n",
      "  How do relational meanings shape network structure in online communities?\n",
      "\n",
      "QUALITATIVE_SOURCES:\n",
      "  Newsgroup posts, interviews, ethnographic notes\n",
      "\n",
      "NETWORK_CONCEPT:\n",
      "  Directed graph of interaction patterns\n",
      "\n",
      "LLM_ROLE:\n",
      "  Provisional extraction and interpretation of relational meanings\n",
      "\n",
      "ETHICAL_RISKS:\n",
      "  Hallucination, misrepresentation, privacy violations\n",
      "\n",
      "MITIGATIONS:\n",
      "  Human validation, anonymization, audit trails\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Research Design Metadata Template\n",
    "research_design = {\n",
    "    \"question\": \"How do relational meanings shape network structure in online communities?\",\n",
    "    \"qualitative_sources\": \"Newsgroup posts, interviews, ethnographic notes\",\n",
    "    \"network_concept\": \"Directed graph of interaction patterns\",\n",
    "    \"llm_role\": \"Provisional extraction and interpretation of relational meanings\",\n",
    "    \"ethical_risks\": \"Hallucination, misrepresentation, privacy violations\",\n",
    "    \"mitigations\": \"Human validation, anonymization, audit trails\"\n",
    "}\n",
    "\n",
    "print(\"RESEARCH DESIGN CHECKLIST:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "for key, value in research_design.items():\n",
    "    print(f\"{key.upper()}:\")\n",
    "    print(f\"  {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Layer\n",
    "\n",
    "Describe who produced the data, in what context, and with what expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA LAYER:\n",
      "============================================================\n",
      "\n",
      "Data Source Metadata:\n",
      "- Producer: Simulated organizational texts\n",
      "- Context: Team collaboration and mentorship\n",
      "- Expectations: Explicit relationship descriptions\n",
      "\n",
      "Data Corpus:\n",
      "                                               text\n",
      "0   Alice and Bob work together on the new project.\n",
      "1  Bob and Carol are friends and often collaborate.\n",
      "2    Carol mentors David, a new member of the team.\n"
     ]
    }
   ],
   "source": [
    "# Data Layer: Qualitative texts\n",
    "texts = [\n",
    "    \"Alice and Bob work together on the new project.\",\n",
    "    \"Bob and Carol are friends and often collaborate.\",\n",
    "    \"Carol mentors David, a new member of the team.\"\n",
    "]\n",
    "\n",
    "df_data = pd.DataFrame({\"text\": texts})\n",
    "\n",
    "print(\"DATA LAYER:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Data Source Metadata:\")\n",
    "print(\"- Producer: Simulated organizational texts\")\n",
    "print(\"- Context: Team collaboration and mentorship\")\n",
    "print(\"- Expectations: Explicit relationship descriptions\")\n",
    "print()\n",
    "print(\"Data Corpus:\")\n",
    "print(df_data.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretive Coding Layer\n",
    "\n",
    "Coding schemes are theoretical instruments. Document their evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERPRETIVE CODING LAYER:\n",
      "============================================================\n",
      "\n",
      "Coding Scheme:\n",
      "  Alice -- Bob: collaborative work\n",
      "  Bob -- Carol: friendship and collaboration\n",
      "  Carol -- David: mentorship\n",
      "\n",
      "Note: Coding schemes evolve through iterative analysis.\n"
     ]
    }
   ],
   "source": [
    "# Interpretive Coding Layer\n",
    "codes = {\n",
    "    (\"Alice\", \"Bob\"): \"collaborative work\",\n",
    "    (\"Bob\", \"Carol\"): \"friendship and collaboration\",\n",
    "    (\"Carol\", \"David\"): \"mentorship\"\n",
    "}\n",
    "\n",
    "print(\"INTERPRETIVE CODING LAYER:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Coding Scheme:\")\n",
    "for pair, code in codes.items():\n",
    "    print(f\"  {pair[0]} -- {pair[1]}: {code}\")\n",
    "print()\n",
    "print(\"Note: Coding schemes evolve through iterative analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Interaction Template\n",
    "\n",
    "For each LLM use, record purpose, prompt, model, output, and researcher decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM INTERACTION TEMPLATE:\n",
      "============================================================\n",
      "\n",
      "Iteration 1:\n",
      "  Text: Alice and Bob work together on the new project.\n",
      "  LLM Output: From the text provided, the following relationship can be extracted:\n",
      "\n",
      "- **Relati...\n",
      "\n",
      "Iteration 2:\n",
      "  Text: Bob and Carol are friends and often collaborate.\n",
      "  LLM Output: 1. **Relationship**: Bob and Carol  \n",
      "   **Type**: Friendship  \n",
      "   **Meaning**: A...\n",
      "\n",
      "Iteration 3:\n",
      "  Text: Carol mentors David, a new member of the team.\n",
      "  LLM Output: 1. **Relationship:** Carol and David  \n",
      "   **Type:** Mentorship  \n",
      "   **Meaning:**...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LLM Log Template\n",
    "llm_log = []\n",
    "\n",
    "print(\"LLM INTERACTION TEMPLATE:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    extraction = get_label(\"openai\", text, query_openai_extraction, \"extraction\")\n",
    "    \n",
    "    log_entry = {\n",
    "        \"iteration\": i + 1,\n",
    "        \"purpose\": \"Extract relational meanings\",\n",
    "        \"input_text\": text[:50],\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"output\": extraction[:100],\n",
    "        \"researcher_decision\": \"Validated against coding scheme\"\n",
    "    }\n",
    "    llm_log.append(log_entry)\n",
    "    \n",
    "    print(f\"Iteration {i+1}:\")\n",
    "    print(f\"  Text: {text}\")\n",
    "    print(f\"  LLM Output: {extraction[:80]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Construction Layer\n",
    "\n",
    "Network edges are interpretive artifacts. Justify inclusion and exclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK CONSTRUCTION LAYER:\n",
      "============================================================\n",
      "\n",
      "Nodes: ['Alice', 'Bob', 'Carol', 'David']\n",
      "Edges: [('Alice', 'Bob'), ('Bob', 'Carol'), ('Carol', 'David')]\n",
      "\n",
      "Edge Meanings:\n",
      "  Alice -- Bob: collaborative work\n",
      "  Bob -- Carol: friendship and collaboration\n",
      "  Carol -- David: mentorship\n"
     ]
    }
   ],
   "source": [
    "# Network Construction Layer\n",
    "G_practice = nx.Graph()\n",
    "\n",
    "# Add edges based on interpretive coding\n",
    "edges_practice = [\n",
    "    (\"Alice\", \"Bob\", {\"meaning\": \"collaborative work\"}),\n",
    "    (\"Bob\", \"Carol\", {\"meaning\": \"friendship and collaboration\"}),\n",
    "    (\"Carol\", \"David\", {\"meaning\": \"mentorship\"})\n",
    "]\n",
    "\n",
    "for u, v, attr in edges_practice:\n",
    "    G_practice.add_edge(u, v, **attr)\n",
    "\n",
    "print(\"NETWORK CONSTRUCTION LAYER:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"Nodes: {list(G_practice.nodes())}\")\n",
    "print(f\"Edges: {list(G_practice.edges())}\")\n",
    "print()\n",
    "print(\"Edge Meanings:\")\n",
    "for u, v, d in G_practice.edges(data=True):\n",
    "    print(f\"  {u} -- {v}: {d['meaning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Layer\n",
    "\n",
    "Ask: What does this network represent? What does it obscure? How does it relate to theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERPRETATION LAYER:\n",
      "============================================================\n",
      "\n",
      "Critical Questions:\n",
      "\n",
      "1. What does this network represent?\n",
      "   - A small team with mentorship and collaborative relationships\n",
      "   - Directed flows of knowledge and support\n",
      "\n",
      "2. What does it obscure?\n",
      "   - Temporal dynamics (how relationships change over time)\n",
      "   - Emotional dimensions (satisfaction, conflict)\n",
      "   - Structural holes and brokerage roles\n",
      "\n",
      "3. How does it relate to theory?\n",
      "   - Social capital theory: Mentorship as knowledge transfer\n",
      "   - Network analysis: Density and clustering\n",
      "   - Qualitative SNA: Meaning-making in relationships\n"
     ]
    }
   ],
   "source": [
    "print(\"INTERPRETATION LAYER:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Critical Questions:\")\n",
    "print()\n",
    "print(\"1. What does this network represent?\")\n",
    "print(\"   - A small team with mentorship and collaborative relationships\")\n",
    "print(\"   - Directed flows of knowledge and support\")\n",
    "print()\n",
    "print(\"2. What does it obscure?\")\n",
    "print(\"   - Temporal dynamics (how relationships change over time)\")\n",
    "print(\"   - Emotional dimensions (satisfaction, conflict)\")\n",
    "print(\"   - Structural holes and brokerage roles\")\n",
    "print()\n",
    "print(\"3. How does it relate to theory?\")\n",
    "print(\"   - Social capital theory: Mentorship as knowledge transfer\")\n",
    "print(\"   - Network analysis: Density and clustering\")\n",
    "print(\"   - Qualitative SNA: Meaning-making in relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethical Reflection Layer\n",
    "\n",
    "Document potential harms, representation risks, and disclosure strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETHICAL REFLECTION LAYER:\n",
      "============================================================\n",
      "\n",
      "Potential Harms:\n",
      "- Misrepresentation of relationships\n",
      "- Privacy violations if identities are disclosed\n",
      "- Stigmatization of certain actors or relationships\n",
      "\n",
      "Representation Risks:\n",
      "- Network visualization may oversimplify complexity\n",
      "- Absence of edges may be misinterpreted as lack of relationship\n",
      "- Centrality measures may be misused for evaluation\n",
      "\n",
      "Disclosure Strategies:\n",
      "- Use anonymization and aggregation\n",
      "- Provide context and caveats\n",
      "- Obtain informed consent for any publication\n",
      "- Allow participants to review and comment\n"
     ]
    }
   ],
   "source": [
    "print(\"ETHICAL REFLECTION LAYER:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Potential Harms:\")\n",
    "print(\"- Misrepresentation of relationships\")\n",
    "print(\"- Privacy violations if identities are disclosed\")\n",
    "print(\"- Stigmatization of certain actors or relationships\")\n",
    "print()\n",
    "print(\"Representation Risks:\")\n",
    "print(\"- Network visualization may oversimplify complexity\")\n",
    "print(\"- Absence of edges may be misinterpreted as lack of relationship\")\n",
    "print(\"- Centrality measures may be misused for evaluation\")\n",
    "print()\n",
    "print(\"Disclosure Strategies:\")\n",
    "print(\"- Use anonymization and aggregation\")\n",
    "print(\"- Provide context and caveats\")\n",
    "print(\"- Obtain informed consent for any publication\")\n",
    "print(\"- Allow participants to review and comment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication Package Checklist\n",
    "\n",
    "Ensure reproducibility and transparency by including all necessary materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICATION PACKAGE CHECKLIST:\n",
      "============================================================\n",
      "\n",
      "               Item Status                          Notes\n",
      "               Code      âœ“  All analysis scripts included\n",
      "            Prompts      âœ“     All LLM prompts documented\n",
      "               Logs      âœ“ Audit trails for all LLM calls\n",
      " Interpretive Notes      âœ“    Coding decisions documented\n",
      "Ethical Disclosures      âœ“   Risks and mitigations listed\n",
      "  Data (Anonymized)      âœ“     Can be shared if consented\n"
     ]
    }
   ],
   "source": [
    "replication_checklist = pd.DataFrame([\n",
    "    {\"Item\": \"Code\", \"Status\": \"âœ“\", \"Notes\": \"All analysis scripts included\"},\n",
    "    {\"Item\": \"Prompts\", \"Status\": \"âœ“\", \"Notes\": \"All LLM prompts documented\"},\n",
    "    {\"Item\": \"Logs\", \"Status\": \"âœ“\", \"Notes\": \"Audit trails for all LLM calls\"},\n",
    "    {\"Item\": \"Interpretive Notes\", \"Status\": \"âœ“\", \"Notes\": \"Coding decisions documented\"},\n",
    "    {\"Item\": \"Ethical Disclosures\", \"Status\": \"âœ“\", \"Notes\": \"Risks and mitigations listed\"},\n",
    "    {\"Item\": \"Data (Anonymized)\", \"Status\": \"âœ“\", \"Notes\": \"Can be shared if consented\"}\n",
    "])\n",
    "\n",
    "print(\"REPLICATION PACKAGE CHECKLIST:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(replication_checklist.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Research Directions\n",
    "\n",
    "Consider these extensions and future research directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN RESEARCH DIRECTIONS:\n",
      "============================================================\n",
      "\n",
      "1. Narrative Multiplexity\n",
      "   - How do different narratives about the same relationship coexist?\n",
      "   - Can we model multiple relational meanings simultaneously?\n",
      "\n",
      "2. Dynamic Relational Meanings\n",
      "   - How do relationship meanings change over time?\n",
      "   - Can LLMs track semantic drift in relationships?\n",
      "\n",
      "3. Role Transitions\n",
      "   - How do actors shift between roles (mentor, peer, subordinate)?\n",
      "   - What triggers role changes?\n",
      "\n",
      "4. Interpretive Uncertainty\n",
      "   - How do we quantify ambiguity in relational meanings?\n",
      "   - Can we model disagreement between coders?\n"
     ]
    }
   ],
   "source": [
    "print(\"OPEN RESEARCH DIRECTIONS:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"1. Narrative Multiplexity\")\n",
    "print(\"   - How do different narratives about the same relationship coexist?\")\n",
    "print(\"   - Can we model multiple relational meanings simultaneously?\")\n",
    "print()\n",
    "print(\"2. Dynamic Relational Meanings\")\n",
    "print(\"   - How do relationship meanings change over time?\")\n",
    "print(\"   - Can LLMs track semantic drift in relationships?\")\n",
    "print()\n",
    "print(\"3. Role Transitions\")\n",
    "print(\"   - How do actors shift between roles (mentor, peer, subordinate)?\")\n",
    "print(\"   - What triggers role changes?\")\n",
    "print()\n",
    "print(\"4. Interpretive Uncertainty\")\n",
    "print(\"   - How do we quantify ambiguity in relational meanings?\")\n",
    "print(\"   - Can we model disagreement between coders?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 6 Takeaway: Seminar Closure\n",
    "\n",
    "LLMs do not make qualitative SNA obsolete. They make its epistemic commitments more visible, more scalable, and more consequential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Final Synthesis with 20 Newsgroups Dataset\n",
    "\n",
    "Apply the complete research design template to the 20 Newsgroups dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ SNAPSHOT NOT FOUND. GENERATING NEW SAMPLE...\n",
      "ðŸ’¾ PERMANENTLY SAVED: news_snapshot_m100_516e4df7.csv\n",
      "\n",
      "--- READY: 100 interactions between 20 nodes ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Researcher_10</td>\n",
       "      <td>Researcher_16</td>\n",
       "      <td>In case you missed it on the news....the first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Researcher_02</td>\n",
       "      <td>Researcher_08</td>\n",
       "      <td>We have no way of knowing because we cann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Researcher_12</td>\n",
       "      <td>Researcher_14</td>\n",
       "      <td>The lengthy article you quote doesn't imply ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Researcher_19</td>\n",
       "      <td>Researcher_18</td>\n",
       "      <td>The recent rise of nostalgia in this group, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Researcher_08</td>\n",
       "      <td>Researcher_12</td>\n",
       "      <td># ## Absolutely nothing, seeing as there is no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source         target  \\\n",
       "0  Researcher_10  Researcher_16   \n",
       "1  Researcher_02  Researcher_08   \n",
       "2  Researcher_12  Researcher_14   \n",
       "3  Researcher_19  Researcher_18   \n",
       "4  Researcher_08  Researcher_12   \n",
       "\n",
       "                                                text  \n",
       "0  In case you missed it on the news....the first...  \n",
       "1       We have no way of knowing because we cann...  \n",
       "2    The lengthy article you quote doesn't imply ...  \n",
       "3  The recent rise of nostalgia in this group, co...  \n",
       "4  # ## Absolutely nothing, seeing as there is no...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "n = 20  # Number of Nodes (Researchers)\n",
    "m = 100  # Number of Edges (Interactions/posts)\n",
    "\n",
    "# Dataset Description\n",
    "# The 20 Newsgroups dataset is a collection of approximately 18,000 newsgroup posts \n",
    "# that originated in the early days of the internet (Usenet) and they can be \n",
    "# displayed as a social network (a directed weighted multigraph) among thousands \n",
    "# of unique nodes/researchers interacting/replying in the posts of the 20 newsgroups.\n",
    "# Taken from sklearn.datasets.fetch_20newsgroups\n",
    "\n",
    "# Generate a unique filename based on m to avoid mixing samples\n",
    "config_hash = hashlib.md5(f\"{m}_newsgroups_s6\".encode()).hexdigest()[:8]\n",
    "SNAPSHOT_FILE = f\"news_snapshot_m{m}_{config_hash}.csv\"\n",
    "\n",
    "# CHECK IF WE ALREADY HAVE THE COMPLETE DATA\n",
    "if os.path.exists(SNAPSHOT_FILE):\n",
    "    print(f\"âœ… LOADING PERMANENT SNAPSHOT: {SNAPSHOT_FILE}\")\n",
    "    interactions = pd.read_csv(SNAPSHOT_FILE)\n",
    "else:\n",
    "    print(f\"ðŸš€ SNAPSHOT NOT FOUND. GENERATING NEW SAMPLE...\")\n",
    "    \n",
    "    # 1. Fetch the big dataset (11,000+ posts)\n",
    "    newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "    full_df = pd.DataFrame({'text': newsgroups.data})\n",
    "    \n",
    "    # 2. Filter and Sample M posts\n",
    "    df = full_df[full_df['text'].str.strip().str.len() > 20].copy()\n",
    "    subset = df.sample(n=m, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # 3. Assign the Social Structure (Source/Target)\n",
    "    user_pool = [f\"Researcher_{i:02d}\" for i in range(n)]\n",
    "    sources = [random.choice(user_pool) for _ in range(m)]\n",
    "    targets = [random.choice([u for u in user_pool if u != s]) for s in sources]\n",
    "\n",
    "    interactions = pd.DataFrame({\n",
    "        \"source\": sources,\n",
    "        \"target\": targets,\n",
    "        \"text\": subset['text'].str[:300].replace('\\n', ' ', regex=True)\n",
    "    })\n",
    "\n",
    "    # 4. IMMEDIATELY SAVE (before LLM processing)\n",
    "    interactions.to_csv(SNAPSHOT_FILE, index=False)\n",
    "    print(f\"ðŸ’¾ PERMANENTLY SAVED: {SNAPSHOT_FILE}\")\n",
    "\n",
    "print(f\"\\n--- READY: {len(interactions)} interactions between {n} nodes ---\")\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Pipeline: Relational Extraction with Meaning Attribution\n",
    "\n",
    "Integrate textual meaning into relational attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL PIPELINE: Relational Extraction\n",
      "============================================================\n",
      "\n",
      "Researcher_13 -> Researcher_16\n",
      "  Type: Neutral\n",
      "  Text:     Ok boys & girls, hang on; here we go!      Christ's Eter...\n",
      "\n",
      "Researcher_05 -> Researcher_01\n",
      "  Type: Positive\n",
      "  Text:     J.N. Darby was one of the founders of the \"Plymouth Bret...\n",
      "\n",
      "Researcher_19 -> Researcher_02\n",
      "  Type: Neutral\n",
      "  Text:  I missed the presentations given in the morning session (wh...\n",
      "\n",
      "Researcher_07 -> Researcher_04\n",
      "  Type: Neutral\n",
      "  Text:  I think the original poster meant opening the mouse, not ju...\n",
      "\n",
      "Researcher_15 -> Researcher_01\n",
      "  Type: Neutral\n",
      "  Text:   [After a small refresh Hasan got on the track again.]     ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample interactions for analysis\n",
    "sample_size = min(5, len(interactions))\n",
    "sample_interactions = interactions.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(\"FINAL PIPELINE: Relational Extraction\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Build final network with meanings\n",
    "G_final = nx.DiGraph()\n",
    "\n",
    "for _, row in sample_interactions.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    text = row['text']\n",
    "    \n",
    "    # Determine tie type based on text content\n",
    "    tie_type = \"Positive\" if any(word in text.lower() for word in [\"good\", \"great\", \"help\", \"support\", \"appreciate\"]) else \"Neutral\"\n",
    "    \n",
    "    # Extract meaning with LLM\n",
    "    meaning = get_label(\"openai\", text, query_openai_extraction, \"final_extraction\")\n",
    "    \n",
    "    # Add edge with attributes\n",
    "    G_final.add_edge(source, target, \n",
    "                     tie_type=tie_type, \n",
    "                     narrative=text[:50],\n",
    "                     meaning=meaning[:50])\n",
    "    \n",
    "    print(f\"{source} -> {target}\")\n",
    "    print(f\"  Type: {tie_type}\")\n",
    "    print(f\"  Text: {text[:60]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Network Summary:\n",
      "Nodes: 9\n",
      "Edges: 5\n",
      "\n",
      "Edges with Qualitative Attributes:\n",
      "Researcher_13 -> Researcher_16: Neutral (    Ok boys & girls, hang on; here we go!      Chr)\n",
      "Researcher_05 -> Researcher_01: Positive (    J.N. Darby was one of the founders of the \"Ply)\n",
      "Researcher_19 -> Researcher_02: Neutral ( I missed the presentations given in the morning s)\n",
      "Researcher_07 -> Researcher_04: Neutral ( I think the original poster meant opening the mou)\n",
      "Researcher_15 -> Researcher_01: Neutral (  [After a small refresh Hasan got on the track ag)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Network Summary:\")\n",
    "print(f\"Nodes: {G_final.number_of_nodes()}\")\n",
    "print(f\"Edges: {G_final.number_of_edges()}\")\n",
    "print()\n",
    "print(\"Edges with Qualitative Attributes:\")\n",
    "for u, v, d in G_final.edges(data=True):\n",
    "    print(f\"{u} -> {v}: {d['tie_type']} ({d['narrative']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"550px\"\n",
       "            src=\"newsgroups_graph_s6.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1482da590>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anonymize for visualization\n",
    "def anonymize_user(username):\n",
    "    return hashlib.sha256(username.encode()).hexdigest()[:8]\n",
    "\n",
    "# Create anonymized version\n",
    "G_anon = nx.DiGraph()\n",
    "for u, v, d in G_final.edges(data=True):\n",
    "    G_anon.add_edge(anonymize_user(u), anonymize_user(v), **d)\n",
    "\n",
    "# Visualize\n",
    "net = Network(height=\"500px\", width=\"100%\", directed=True, bgcolor=\"#ffffff\")\n",
    "\n",
    "# Add Nodes (labels only)\n",
    "for node in G_anon.nodes():\n",
    "    net.add_node(\n",
    "        node, \n",
    "        label=node, \n",
    "        shape='dot',\n",
    "        size=1,\n",
    "        color='#ffffff',\n",
    "        borderWidth=0,\n",
    "        font={'size': 12, 'color': 'black', 'align': 'center'}\n",
    "    )\n",
    "    \n",
    "# Add Edges with colors based on tie type\n",
    "for source, target, d in G_anon.edges(data=True):\n",
    "    edge_color = '#00aa00' if d.get('tie_type') == 'Positive' else '#cccccc'\n",
    "    net.add_edge(\n",
    "        source, \n",
    "        target, \n",
    "        color=edge_color,\n",
    "        arrows={'to': {'enabled': True, 'scaleFactor': 0.5}},\n",
    "        smooth={'type': 'curvedCW', 'roundness': 0.2},\n",
    "        title=d.get('meaning', 'N/A')\n",
    "    )\n",
    "\n",
    "# Physics\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": { \"gravitationalConstant\": -3000, \"springLength\": 150 }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "html_content = net.generate_html()\n",
    "with open(\"newsgroups_graph_s6.html\", \"w\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "IPython.display.IFrame(src=\"newsgroups_graph_s6.html\", width='100%', height='550px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
