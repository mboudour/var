{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">¬© 2026 Moses Boudourides. All Rights Reserved.</div>\n",
    "\n",
    "# LLMs for Qualitative and Mixed-Methods Social Network Analysis (SNA)\n",
    "## Moses Boudourides\n",
    "\n",
    "# Session 4: Research Designs with LLMs and Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import hashlib\n",
    "import random\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import IPython\n",
    "from openai import OpenAI\n",
    "# import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. & 2. KEY LOADING & INITIALIZATION ---\n",
    "\n",
    "# Force Google to use REST to avoid ALTS/GCP credential errors\n",
    "os.environ[\"GOOGLE_API_USE_MTLS\"] = \"never\" \n",
    "\n",
    "def get_api_key(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return f.read().strip().replace('\"', '').replace(\"'\", \"\")\n",
    "    return None\n",
    "\n",
    "oa_key = get_api_key(\"openai_key.txt\")\n",
    "# gem_key = get_api_key(\"gemini_key.txt\")\n",
    "\n",
    "# Initialize OpenAI\n",
    "client_oa = OpenAI(api_key=oa_key)\n",
    "\n",
    "# # Initialize Gemini using 'rest' transport to bypass gRPC/ALTS errors\n",
    "# genai.configure(api_key=gem_key, transport='rest')\n",
    "\n",
    "# # Dynamic Model Selection\n",
    "# available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
    "# target_model = 'gemini-1.5-flash' if 'models/gemini-1.5-flash' in available_models else available_models[0].split('/')[-1]\n",
    "# model_gemini = genai.GenerativeModel(target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sequential and Parallel Research Designs with LLMs\n",
    "\n",
    "**Goal:**  \n",
    "Illustrate sequential and parallel design patterns for LLM-augmented qualitative and mixed-methods SNA.\n",
    "\n",
    "This notebook focuses on **design logic**, not performance. LLM outputs are always provisional and subject to interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rely on Nina when sensitive issues arise.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul formally supervises my work but offers li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nina and Paul often disagree behind the scenes.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0        I rely on Nina when sensitive issues arise.\n",
       "1  Paul formally supervises my work but offers li...\n",
       "2    Nina and Paul often disagree behind the scenes."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. DATA & PERSISTENT QUERY STEP ---\n",
    "\n",
    "# 2. Persistence Logic\n",
    "CACHE_FILE = \"llm_cache_s4.json\"\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"r\") as f:\n",
    "        cache = json.load(f)\n",
    "else:\n",
    "    cache = {}\n",
    "\n",
    "def get_label(model_id, text, api_func, prompt_type=\"design\"):\n",
    "    # Unique key ensures cache stays valid even if prompt or text changes\n",
    "    cache_key = f\"{model_id}_{prompt_type}_{text[:50]}\"\n",
    "    \n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    # Cache Miss: Call API\n",
    "    result = api_func(text)\n",
    "    cache[cache_key] = result\n",
    "    \n",
    "    # Save updated cache to disk\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump(cache, f)\n",
    "    return result\n",
    "\n",
    "# 3. API Execution Wrappers\n",
    "def query_openai_design(text, design_type=\"sequential\"):\n",
    "    if design_type == \"sequential\":\n",
    "        prompt = f\"\"\"Analyze this text for relational patterns. Identify:\n",
    "1. Trust relations\n",
    "2. Formal authority structures\n",
    "3. Hidden conflicts or tensions\n",
    "\n",
    "Text: {text}\"\"\"\n",
    "    else:  # parallel\n",
    "        prompt = f\"\"\"Describe the roles and relationships of actors in this text.\n",
    "Focus on their positions, responsibilities, and interpersonal dynamics.\n",
    "\n",
    "Text: {text}\"\"\"\n",
    "    \n",
    "    res = client_oa.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return res.choices[0].message.content.strip()\n",
    "\n",
    "# Small qualitative corpus\n",
    "texts_small = [\n",
    "    \"I rely on Nina when sensitive issues arise.\",\n",
    "    \"Paul formally supervises my work but offers little guidance.\",\n",
    "    \"Nina and Paul often disagree behind the scenes.\"\n",
    "]\n",
    "\n",
    "df_small = pd.DataFrame({\"text\": texts_small})\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Design: Phase 1 (Qualitative Anchor)\n",
    "\n",
    "We begin with a small qualitative corpus to establish meaning and identify key concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1: QUALITATIVE ANCHOR\n",
      "============================================================\n",
      "\n",
      "Qualitative Insights from Small Corpus:\n",
      "- Trust relations: Nina is a trusted advisor for sensitive issues\n",
      "- Formal authority: Paul has formal supervisory role but weak support\n",
      "- Hidden conflict: Nina and Paul disagree behind the scenes\n",
      "\n",
      "These concepts will guide Phase 2 LLM analysis.\n"
     ]
    }
   ],
   "source": [
    "print(\"PHASE 1: QUALITATIVE ANCHOR\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Qualitative Insights from Small Corpus:\")\n",
    "print(\"- Trust relations: Nina is a trusted advisor for sensitive issues\")\n",
    "print(\"- Formal authority: Paul has formal supervisory role but weak support\")\n",
    "print(\"- Hidden conflict: Nina and Paul disagree behind the scenes\")\n",
    "print()\n",
    "print(\"These concepts will guide Phase 2 LLM analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Design: Phase 2 (LLM-Assisted Scaling)\n",
    "\n",
    "We use the LLM to analyze the qualitative corpus using the Phase 1 concepts, scaling up the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 2: LLM-ASSISTED SCALING\n",
      "============================================================\n",
      "\n",
      "Text 1: I rely on Nina when sensitive issues arise.\n",
      "LLM Analysis:\n",
      "Analyzing the text \"I rely on Nina when sensitive issues arise,\" we can identify the following relational patterns:\n",
      "\n",
      "1. **Trust Relations**:\n",
      "   - The speaker has a trust relationship with Nina, as indicated by the phrase \"I rely on Nina.\" This suggests that the speaker feels comfortable turning to Nina for support or guidance in sensitive situations, implying a level of trust in her judgment or ability to handle such matters.\n",
      "\n",
      "2. **Formal Authority Structures**:\n",
      "   - The text does not explicitly mention any formal authority structures. However, the reliance on Nina could imply that she holds a certain position of influence or expertise in handling sensitive issues, even if that authority is not formally defined. Without additional context, it's unclear whether Nina has an official role or title that grants her formal authority.\n",
      "\n",
      "3. **Hidden Conflicts or Tensions**:\n",
      "   - While the text does not directly indicate any hidden conflicts or tensions, the fact that the speaker resorts to Nina specifically for \"sensitive issues\" may imply that there are underlying complexities or challenges in the broader context. The use of the term \"sensitive\" suggests that these issues may involve emotional or contentious elements, which could hint at potential conflicts with others that are not overtly expressed in the text.\n",
      "\n",
      "Overall, this brief statement reveals a trust dynamic centered on Nina, hints at her potential role within a broader authority structure, and suggests the presence of complex emotional or relational factors at play.\n",
      "------------------------------------------------------------\n",
      "Text 2: Paul formally supervises my work but offers little guidance.\n",
      "LLM Analysis:\n",
      "Based on the provided text, we can analyze the relational patterns as follows:\n",
      "\n",
      "1. **Trust Relations**:\n",
      "   - The phrase \"offers little guidance\" suggests a lack of trust or confidence in Paul's ability or willingness to provide support. This may indicate that the speaker feels unsupported or uncertain about the relationship, which can erode trust. The speaker may not feel comfortable seeking help or advice from Paul, implying a potentially weak trust relationship.\n",
      "\n",
      "2. **Formal Authority Structures**:\n",
      "   - The statement \"Paul formally supervises my work\" clearly establishes a formal authority structure where Paul holds a supervisory role over the speaker. This indicates a hierarchical relationship, where Paul is expected to provide oversight and direction in the speaker's work. However, the lack of guidance also raises questions about the effectiveness of this authority.\n",
      "\n",
      "3. **Hidden Conflicts or Tensions**:\n",
      "   - The tension arises from the contrast between the expectation of supervision and the reality of receiving \"little guidance.\" This discrepancy may lead to feelings of frustration or resentment from the speaker towards Paul. The speaker may feel that Paul is not fulfilling his supervisory role adequately, which could result in a conflict of expectations. Additionally, if the speaker relies on guidance for their work, the lack thereof could create further stress or conflict in their professional relationship.\n",
      "\n",
      "In summary, the text reveals a formal authority structure but highlights issues with trust and potential conflict stemming from inadequate guidance.\n",
      "------------------------------------------------------------\n",
      "Text 3: Nina and Paul often disagree behind the scenes.\n",
      "LLM Analysis:\n",
      "Based on the provided text, we can analyze the relational patterns as follows:\n",
      "\n",
      "1. **Trust Relations:**\n",
      "   - The phrase \"often disagree behind the scenes\" suggests a lack of open communication or transparency between Nina and Paul. This implies that they may not fully trust each other to express their disagreements openly. Trust relations might be strained, indicating that they might not be comfortable sharing their differing opinions in front of others.\n",
      "\n",
      "2. **Formal Authority Structures:**\n",
      "   - The text does not explicitly mention any formal authority structures. However, the context of disagreement suggests that there may be a power dynamic at play. If Nina and Paul are colleagues or team members, their disagreements could indicate differing levels of influence or authority within their roles, although this is not directly stated in the text.\n",
      "\n",
      "3. **Hidden Conflicts or Tensions:**\n",
      "   - The mention of disagreement \"behind the scenes\" strongly indicates hidden conflicts or tensions. This suggests that while they may present a united front publicly or work collaboratively, there are underlying issues that are not being addressed openly. This can lead to unresolved tensions that might affect their working relationship or the broader team dynamics.\n",
      "\n",
      "In summary, the text suggests a complex dynamic between Nina and Paul characterized by a lack of trust, potential authority differences, and underlying conflicts that could impact their interactions and teamwork.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Phase 2 complete: LLM has identified patterns using Phase 1 concepts.\n"
     ]
    }
   ],
   "source": [
    "print(\"PHASE 2: LLM-ASSISTED SCALING\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "for i, text in enumerate(texts_small):\n",
    "    analysis = get_label(\"openai\", text, lambda t: query_openai_design(t, \"sequential\"), \"sequential_phase2\")\n",
    "    print(f\"Text {i+1}: {text}\")\n",
    "    print(f\"LLM Analysis:\\n{analysis}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\nPhase 2 complete: LLM has identified patterns using Phase 1 concepts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Design: Phase 3 (Interpretive Return)\n",
    "\n",
    "LLM output highlights candidates for closer qualitative analysis. Researchers return to cases, not summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 3: INTERPRETIVE RETURN\n",
      "============================================================\n",
      "\n",
      "Researcher Reflection:\n",
      "- LLM outputs are candidates for closer analysis, not conclusions\n",
      "- Return to original texts to verify and contextualize\n",
      "- Refine theoretical understanding based on case details\n",
      "- Maintain interpretive control throughout\n",
      "\n",
      "Key principle: The researcher, not the LLM, makes final interpretations.\n"
     ]
    }
   ],
   "source": [
    "print(\"PHASE 3: INTERPRETIVE RETURN\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Researcher Reflection:\")\n",
    "print(\"- LLM outputs are candidates for closer analysis, not conclusions\")\n",
    "print(\"- Return to original texts to verify and contextualize\")\n",
    "print(\"- Refine theoretical understanding based on case details\")\n",
    "print(\"- Maintain interpretive control throughout\")\n",
    "print()\n",
    "print(\"Key principle: The researcher, not the LLM, makes final interpretations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Design: Human vs LLM Analysis\n",
    "\n",
    "We analyze the same data independently using human coding and LLM analysis, then compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARALLEL DESIGN: HUMAN CODING\n",
      "============================================================\n",
      "\n",
      "Human Coding Results:\n",
      "  Nina: Trusted advisor - provides support for sensitive issues\n",
      "  Paul: Formal authority with weak support - supervises but offers little guidance\n",
      "  Relationship: Hidden conflict - Nina and Paul disagree behind the scenes\n"
     ]
    }
   ],
   "source": [
    "print(\"PARALLEL DESIGN: HUMAN CODING\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "human_codes = {\n",
    "    \"Nina\": \"Trusted advisor - provides support for sensitive issues\",\n",
    "    \"Paul\": \"Formal authority with weak support - supervises but offers little guidance\",\n",
    "    \"Relationship\": \"Hidden conflict - Nina and Paul disagree behind the scenes\"\n",
    "}\n",
    "\n",
    "print(\"Human Coding Results:\")\n",
    "for actor, code in human_codes.items():\n",
    "    print(f\"  {actor}: {code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PARALLEL DESIGN: LLM CODING\n",
      "============================================================\n",
      "\n",
      "LLM Coding Results:\n",
      "In the provided text, the roles and relationships of the actors‚ÄîNina and Paul‚Äîcan be analyzed as follows:\n",
      "\n",
      "1. **Nina**:\n",
      "   - **Position**: Nina appears to be a key support figure, potentially a colleague or peer, who is trusted by the speaker to handle sensitive issues.\n",
      "   - **Responsibilities**: Her primary responsibility seems to be providing emotional or strategic support during challenging situations. The speaker relies on her for assistance in navigating sensitive matters, indicating that Nina likely has experience or insight that the speaker values.\n",
      "   - **Interpersonal Dynamics**: The relationship between Nina and the speaker is one of trust and reliance. The speaker feels comfortable turning to Nina for support, suggesting a collaborative and possibly empathetic dynamic.\n",
      "\n",
      "2. **Paul**:\n",
      "   - **Position**: Paul holds a formal supervisory role over the speaker‚Äôs work, indicating a level of authority and responsibility for overseeing the speaker's tasks and performance.\n",
      "   - **Responsibilities**: As a supervisor, Paul is expected to guide and mentor the speaker. However, the text suggests that he does not provide much practical guidance, which could indicate a lack of engagement or a more hands-off management style.\n",
      "   - **Interpersonal Dynamics**: The relationship between Paul and the speaker seems to lack depth and support, as the speaker feels that Paul‚Äôs supervision is insufficient. Furthermore, the mention of Paul often disagreeing with Nina behind the scenes introduces an element of tension. This indicates that Paul and Nina may have conflicting perspectives or approaches to their work, which could indirectly affect the speaker‚Äôs experience, especially if the speaker is caught in the middle of their disagreements.\n",
      "\n",
      "3. **Nina and Paul**:\n",
      "   - **Relationship**: Nina and Paul have a complex dynamic characterized by disagreement. This behind-the-scenes conflict suggests that they may have differing opinions on how to handle certain issues or on broader work-related philosophies.\n",
      "   - **Impact on the Speaker**: The tension between Nina and Paul could create a challenging environment for the speaker, who relies on Nina for support while also needing to navigate the formal authority of Paul. This situation may place the speaker in a delicate position, as they might have to balance the expectations of both individuals.\n",
      "\n",
      "Overall, the text highlights a network of relationships where Nina serves as a supportive ally to the speaker, while Paul fulfills a formal supervisory role but lacks the guidance expected. The underlying tensions between Nina and Paul could complicate the speaker's position further, indicating a nuanced interplay of authority, support, and conflict within the workplace.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPARALLEL DESIGN: LLM CODING\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "def query_openai_roles(text):\n",
    "    prompt = f\"\"\"Describe the roles and relationships of actors in this text.\n",
    "Focus on their positions, responsibilities, and interpersonal dynamics.\n",
    "\n",
    "Text: {text}\"\"\"\n",
    "    res = client_oa.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return res.choices[0].message.content.strip()\n",
    "\n",
    "# Generate LLM coding for the corpus\n",
    "corpus_text = \"\\n\".join(texts_small)\n",
    "llm_analysis = get_label(\"openai\", corpus_text, query_openai_roles, \"parallel_llm_coding\")\n",
    "\n",
    "print(\"LLM Coding Results:\")\n",
    "print(llm_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Parallel Analyses\n",
    "\n",
    "Where do human and LLM interpretations converge? Where do they diverge? What does divergence reveal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARING PARALLEL ANALYSES\n",
      "============================================================\n",
      "\n",
      "Convergences:\n",
      "- Both human and LLM identify Nina as a trusted advisor\n",
      "- Both recognize Paul's formal authority with limited support\n",
      "- Both note tension between Nina and Paul\n",
      "\n",
      "Divergences:\n",
      "- LLM may emphasize different aspects of relationships\n",
      "- LLM may infer motivations not explicitly stated\n",
      "- Human codes may capture nuances LLM misses\n",
      "\n",
      "Analytic Resource:\n",
      "Differences between human and LLM analysis are opportunities for deeper investigation.\n",
      "They reveal what each method captures and what it misses.\n"
     ]
    }
   ],
   "source": [
    "print(\"COMPARING PARALLEL ANALYSES\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Convergences:\")\n",
    "print(\"- Both human and LLM identify Nina as a trusted advisor\")\n",
    "print(\"- Both recognize Paul's formal authority with limited support\")\n",
    "print(\"- Both note tension between Nina and Paul\")\n",
    "print()\n",
    "print(\"Divergences:\")\n",
    "print(\"- LLM may emphasize different aspects of relationships\")\n",
    "print(\"- LLM may infer motivations not explicitly stated\")\n",
    "print(\"- Human codes may capture nuances LLM misses\")\n",
    "print()\n",
    "print(\"Analytic Resource:\")\n",
    "print(\"Differences between human and LLM analysis are opportunities for deeper investigation.\")\n",
    "print(\"They reveal what each method captures and what it misses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Ethical Implementation\n",
    "\n",
    "Before network construction, we implement data cleaning and ethical safeguards including anonymization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANED DATA:\n",
      "      user                                       clean_text\n",
      "0    Alice  i really appreciate @bob's help on the project.\n",
      "1      Bob  thanks @alice! @charlie also contributed a lot.\n",
      "2  Charlie        great collaboration with @alice and @bob!\n"
     ]
    }
   ],
   "source": [
    "# Simulated raw data from a social media scrape\n",
    "raw_data = [\n",
    "    {\"user\": \"Alice\", \"text\": \"I really appreciate @Bob's help on the project.\", \"timestamp\": \"2023-10-01\"},\n",
    "    {\"user\": \"Bob\", \"text\": \"Thanks @Alice! @Charlie also contributed a lot.\", \"timestamp\": \"2023-10-02\"},\n",
    "    {\"user\": \"Charlie\", \"text\": \"Great collaboration with @Alice and @Bob!\", \"timestamp\": \"2023-10-03\"}\n",
    "]\n",
    "\n",
    "df_raw = pd.DataFrame(raw_data)\n",
    "\n",
    "# Simple cleaning: Ensure lowercase and remove special characters if needed\n",
    "df_raw['clean_text'] = df_raw['text'].str.lower()\n",
    "\n",
    "print(\"CLEANED DATA:\")\n",
    "print(df_raw[['user', 'clean_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethical Implementation: Anonymization\n",
    "\n",
    "Protect participant identity while maintaining network structure using hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANONYMIZED USER MAPPING:\n",
      "      user anon_user\n",
      "0    Alice  3bc51062\n",
      "1      Bob  cd9fb1e1\n",
      "2  Charlie  6e81b125\n",
      "\n",
      "Note: Anonymization preserves network structure while protecting identity.\n"
     ]
    }
   ],
   "source": [
    "# Responsible Use: Anonymizing PII\n",
    "def anonymize_user(username):\n",
    "    # Using a hash to protect identity while maintaining network structure\n",
    "    return hashlib.sha256(username.encode()).hexdigest()[:8]\n",
    "\n",
    "df_raw['anon_user'] = df_raw['user'].apply(anonymize_user)\n",
    "\n",
    "print(\"ANONYMIZED USER MAPPING:\")\n",
    "print(df_raw[['user', 'anon_user']])\n",
    "print()\n",
    "print(\"Note: Anonymization preserves network structure while protecting identity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational Extraction with Audit Trail\n",
    "\n",
    "Extract relationships from text while maintaining a complete audit trail of decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIT TRAIL SUMMARY:\n",
      "  source_user                                       input_text  \\\n",
      "0       Alice  i really appreciate @bob's help on the project.   \n",
      "1         Bob  thanks @alice! @charlie also contributed a lot.   \n",
      "2         Bob  thanks @alice! @charlie also contributed a lot.   \n",
      "3     Charlie        great collaboration with @alice and @bob!   \n",
      "4     Charlie        great collaboration with @alice and @bob!   \n",
      "\n",
      "  identified_target sentiment_assigned                     logic  \n",
      "0               Bob           Positive  Mention-based extraction  \n",
      "1           Charlie            Neutral  Mention-based extraction  \n",
      "2             Alice            Neutral  Mention-based extraction  \n",
      "3               Bob           Positive  Mention-based extraction  \n",
      "4             Alice           Positive  Mention-based extraction  \n",
      "\n",
      "The audit trail documents every extraction decision for transparency and review.\n"
     ]
    }
   ],
   "source": [
    "# Relational Extraction and Audit Trail\n",
    "audit_trail = []\n",
    "\n",
    "def extract_ties_with_audit(text, user_id):\n",
    "    # In practice, this would call an LLM API\n",
    "    # Prompt: \"Identify mentioned users and the sentiment of the interaction.\"\n",
    "    extracted_targets = []\n",
    "    if \"@bob\" in text:\n",
    "        extracted_targets.append(\"Bob\")\n",
    "    if \"@charlie\" in text:\n",
    "        extracted_targets.append(\"Charlie\")\n",
    "    if \"@alice\" in text:\n",
    "        extracted_targets.append(\"Alice\")\n",
    "    \n",
    "    sentiment = \"Positive\" if \"appreciate\" in text or \"great\" in text else \"Neutral\"\n",
    "    \n",
    "    # Log the decision for the audit trail\n",
    "    for target in extracted_targets:\n",
    "        audit_trail.append({\n",
    "            \"source_user\": user_id,\n",
    "            \"input_text\": text[:50],\n",
    "            \"identified_target\": target,\n",
    "            \"sentiment_assigned\": sentiment,\n",
    "            \"logic\": \"Mention-based extraction\"\n",
    "        })\n",
    "    \n",
    "    return extracted_targets, sentiment\n",
    "\n",
    "# Apply extraction\n",
    "df_raw[['targets', 'sentiment']] = df_raw.apply(\n",
    "    lambda x: pd.Series(extract_ties_with_audit(x['clean_text'], x['user'])), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Reviewing the Audit Trail\n",
    "audit_df = pd.DataFrame(audit_trail)\n",
    "\n",
    "print(\"AUDIT TRAIL SUMMARY:\")\n",
    "print(audit_df)\n",
    "print()\n",
    "print(\"The audit trail documents every extraction decision for transparency and review.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Audit Trail Template\n",
    "\n",
    "For each LLM use, document purpose, prompt, model, output, and researcher decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIT TRAIL FOR LLM OPERATIONS:\n",
      "               stage                                       purpose                                prompt        model                                                decision\n",
      "0    Phase 2 scaling  Identify trust, authority, conflict patterns  Analyze text for relational patterns  gpt-4o-mini  Used for case selection and hypothesis generation only\n",
      "1  Parallel analysis                   Compare human vs LLM coding      Describe roles and relationships  gpt-4o-mini           Used to identify convergences and divergences\n",
      "\n",
      "This template enables transparency and enables peer review of LLM use.\n"
     ]
    }
   ],
   "source": [
    "# Audit Trail Example for LLM Operations\n",
    "audit_trail_llm = pd.DataFrame([\n",
    "    {\n",
    "        \"stage\": \"Phase 2 scaling\",\n",
    "        \"purpose\": \"Identify trust, authority, conflict patterns\",\n",
    "        \"prompt\": \"Analyze text for relational patterns\",\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"decision\": \"Used for case selection and hypothesis generation only\"\n",
    "    },\n",
    "    {\n",
    "        \"stage\": \"Parallel analysis\",\n",
    "        \"purpose\": \"Compare human vs LLM coding\",\n",
    "        \"prompt\": \"Describe roles and relationships\",\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"decision\": \"Used to identify convergences and divergences\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"AUDIT TRAIL FOR LLM OPERATIONS:\")\n",
    "print(audit_trail_llm.to_string())\n",
    "print()\n",
    "print(\"This template enables transparency and enables peer review of LLM use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validity Reflection\n",
    "\n",
    "Design choices shape what counts as data, interpretation, and defensible claims. LLMs amplify the consequences of weak design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDITY REFLECTION\n",
      "============================================================\n",
      "\n",
      "Design Choices and Their Consequences:\n",
      "\n",
      "1. What counts as DATA:\n",
      "   - Small qualitative corpus vs. large corpus\n",
      "   - Raw text vs. cleaned text\n",
      "   - Anonymized vs. identified participants\n",
      "\n",
      "2. What counts as INTERPRETATION:\n",
      "   - Human coding vs. LLM analysis\n",
      "   - Convergence vs. divergence\n",
      "   - Provisional vs. final claims\n",
      "\n",
      "3. What claims are DEFENSIBLE:\n",
      "   - Claims grounded in qualitative anchor\n",
      "   - Claims verified through interpretive return\n",
      "   - Claims documented in audit trail\n",
      "\n",
      "LLMs amplify the consequences of weak design choices.\n",
      "Transparent design is essential for validity.\n"
     ]
    }
   ],
   "source": [
    "print(\"VALIDITY REFLECTION\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Design Choices and Their Consequences:\")\n",
    "print()\n",
    "print(\"1. What counts as DATA:\")\n",
    "print(\"   - Small qualitative corpus vs. large corpus\")\n",
    "print(\"   - Raw text vs. cleaned text\")\n",
    "print(\"   - Anonymized vs. identified participants\")\n",
    "print()\n",
    "print(\"2. What counts as INTERPRETATION:\")\n",
    "print(\"   - Human coding vs. LLM analysis\")\n",
    "print(\"   - Convergence vs. divergence\")\n",
    "print(\"   - Provisional vs. final claims\")\n",
    "print()\n",
    "print(\"3. What claims are DEFENSIBLE:\")\n",
    "print(\"   - Claims grounded in qualitative anchor\")\n",
    "print(\"   - Claims verified through interpretive return\")\n",
    "print(\"   - Claims documented in audit trail\")\n",
    "print()\n",
    "print(\"LLMs amplify the consequences of weak design choices.\")\n",
    "print(\"Transparent design is essential for validity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 4 Takeaway\n",
    "\n",
    "LLMs do not simplify research design. They make design choices more consequential and more visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Applying Research Designs to 20 Newsgroups Dataset\n",
    "\n",
    "Now we apply the sequential and parallel design patterns to a larger dataset: the 20 Newsgroups corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ SNAPSHOT NOT FOUND. GENERATING NEW SAMPLE...\n",
      "üíæ PERMANENTLY SAVED: news_snapshot_m100_f13de034.csv\n",
      "\n",
      "--- READY: 100 interactions between 20 nodes ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Researcher_15</td>\n",
       "      <td>Researcher_12</td>\n",
       "      <td>In case you missed it on the news....the first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Researcher_05</td>\n",
       "      <td>Researcher_11</td>\n",
       "      <td>We have no way of knowing because we cann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Researcher_02</td>\n",
       "      <td>Researcher_00</td>\n",
       "      <td>The lengthy article you quote doesn't imply ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Researcher_11</td>\n",
       "      <td>Researcher_00</td>\n",
       "      <td>The recent rise of nostalgia in this group, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Researcher_09</td>\n",
       "      <td>Researcher_01</td>\n",
       "      <td># ## Absolutely nothing, seeing as there is no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source         target  \\\n",
       "0  Researcher_15  Researcher_12   \n",
       "1  Researcher_05  Researcher_11   \n",
       "2  Researcher_02  Researcher_00   \n",
       "3  Researcher_11  Researcher_00   \n",
       "4  Researcher_09  Researcher_01   \n",
       "\n",
       "                                                text  \n",
       "0  In case you missed it on the news....the first...  \n",
       "1       We have no way of knowing because we cann...  \n",
       "2    The lengthy article you quote doesn't imply ...  \n",
       "3  The recent rise of nostalgia in this group, co...  \n",
       "4  # ## Absolutely nothing, seeing as there is no...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "n = 20  # Number of Nodes (Researchers)\n",
    "m = 100  # Number of Edges (Interactions/posts)\n",
    "\n",
    "# Dataset Description\n",
    "# The 20 Newsgroups dataset is a collection of approximately 18,000 newsgroup posts \n",
    "# that originated in the early days of the internet (Usenet) and they can be \n",
    "# displayed as a social network (a directed weighted multigraph) among thousands \n",
    "# of unique nodes/researchers interacting/replying in the posts of the 20 newsgroups.\n",
    "# Taken from sklearn.datasets.fetch_20newsgroups\n",
    "\n",
    "# Generate a unique filename based on m to avoid mixing samples\n",
    "config_hash = hashlib.md5(f\"{m}_newsgroups_s4\".encode()).hexdigest()[:8]\n",
    "SNAPSHOT_FILE = f\"news_snapshot_m{m}_{config_hash}.csv\"\n",
    "\n",
    "# CHECK IF WE ALREADY HAVE THE COMPLETE DATA\n",
    "if os.path.exists(SNAPSHOT_FILE):\n",
    "    print(f\"‚úÖ LOADING PERMANENT SNAPSHOT: {SNAPSHOT_FILE}\")\n",
    "    interactions = pd.read_csv(SNAPSHOT_FILE)\n",
    "else:\n",
    "    print(f\"üöÄ SNAPSHOT NOT FOUND. GENERATING NEW SAMPLE...\")\n",
    "    \n",
    "    # 1. Fetch the big dataset (11,000+ posts)\n",
    "    newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "    full_df = pd.DataFrame({'text': newsgroups.data})\n",
    "    \n",
    "    # 2. Filter and Sample M posts\n",
    "    df = full_df[full_df['text'].str.strip().str.len() > 20].copy()\n",
    "    subset = df.sample(n=m, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # 3. Assign the Social Structure (Source/Target)\n",
    "    user_pool = [f\"Researcher_{i:02d}\" for i in range(n)]\n",
    "    sources = [random.choice(user_pool) for _ in range(m)]\n",
    "    targets = [random.choice([u for u in user_pool if u != s]) for s in sources]\n",
    "\n",
    "    interactions = pd.DataFrame({\n",
    "        \"source\": sources,\n",
    "        \"target\": targets,\n",
    "        \"text\": subset['text'].str[:300].replace('\\n', ' ', regex=True)\n",
    "    })\n",
    "\n",
    "    # 4. IMMEDIATELY SAVE (before LLM processing)\n",
    "    interactions.to_csv(SNAPSHOT_FILE, index=False)\n",
    "    print(f\"üíæ PERMANENTLY SAVED: {SNAPSHOT_FILE}\")\n",
    "\n",
    "print(f\"\\n--- READY: {len(interactions)} interactions between {n} nodes ---\")\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Design on Newsgroups: Phase 1 (Qualitative Anchor)\n",
    "\n",
    "Select a small sample of newsgroup posts for qualitative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1: QUALITATIVE ANCHOR (Newsgroups Sample)\n",
      "============================================================\n",
      "\n",
      "Post 83:\n",
      "From: Researcher_15 To: Researcher_12\n",
      "Text:     Ok boys & girls, hang on; here we go!      Christ's Eternal Gospel               Robinson & Robinson    The Dead Sea Scrolls & the NT         WS L...\n",
      "------------------------------------------------------------\n",
      "Post 53:\n",
      "From: Researcher_03 To: Researcher_07\n",
      "Text:     J.N. Darby was one of the founders of the \"Plymouth Brethren\" and an early supporter of dispensationalism.  F.F. Bruce highly approved of his tran...\n",
      "------------------------------------------------------------\n",
      "Post 70:\n",
      "From: Researcher_11 To: Researcher_17\n",
      "Text:  I missed the presentations given in the morning session (when Shea gave his \"rambling and almost inaudible\" presentation), but I did attend the after...\n",
      "------------------------------------------------------------\n",
      "\n",
      "These posts form the qualitative anchor for Phase 2 analysis.\n"
     ]
    }
   ],
   "source": [
    "# Sample a subset for detailed qualitative analysis\n",
    "sample_size = min(3, len(interactions))\n",
    "sample_interactions = interactions.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(\"PHASE 1: QUALITATIVE ANCHOR (Newsgroups Sample)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "for idx, row in sample_interactions.iterrows():\n",
    "    print(f\"Post {idx}:\")\n",
    "    print(f\"From: {row['source']} To: {row['target']}\")\n",
    "    print(f\"Text: {row['text'][:150]}...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\nThese posts form the qualitative anchor for Phase 2 analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Design on Newsgroups: Phase 2 (LLM-Assisted Scaling)\n",
    "\n",
    "Use LLM to analyze the full newsgroups dataset using Phase 1 concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 2: LLM-ASSISTED SCALING (Newsgroups)\n",
      "============================================================\n",
      "\n",
      "Post 83:     Ok boys & girls, hang on; here we go!      Christ's Eternal Gospel          ...\n",
      "LLM Analysis:\n",
      "To analyze the provided text for relational patterns, we can break down the components as follows:\n",
      "\n",
      "### 1. Trust Relations\n",
      "- The phrase \"Ok boys & girls, hang on; here we go!\" suggests a casual and friendly tone, indicating a level of trust and camaraderie among the audience, likely implying that the speaker feels comfortable engaging with the group.\n",
      "- The mention of various authors and works (e.g., \"Robinson & Robinson,\" \"RH Eisenman\") indicates that the speaker may trust the credibility of these individuals and their scholarly contributions. This can suggest an implicit endorsement of their perspectives and interpretations, which could influence the audience's trust in the information presented.\n",
      "\n",
      "### 2. Formal Authority Structures\n",
      "- The structure of the text presents a list of authors and their works, suggesting a hierarchy of knowledge or expertise. For instance, \"WS LaSor\" and \"RH Eisenman\" appear to be recognized scholars in their fields, indicating that they hold formal authority on topics related to biblical texts and historical analysis.\n",
      "- The inclusion of different scholarly works suggests a formal academic context where certain individuals (like LaSor and Eisenman) are authorities in their respective areas (e.g., the Dead Sea Scrolls, Maccabees). This can imply that the audience is expected to acknowledge these figures as credible sources of information.\n",
      "\n",
      "### 3. Hidden Conflicts or Tensions\n",
      "- The mention of authors with differing focuses (e.g., \"James the Just in Habakkuk Pesher\" versus \"Dead Sea Scrolls Uncovered\") may indicate underlying tensions within the scholarly discourse about interpretations of biblical texts. The differences in focus can highlight contrasting views on theology or historical context, which may lead to debates or conflicts among scholars or within the audience.\n",
      "- The casual and engaging tone (‚ÄúOk boys & girls, hang on; here we go!‚Äù) juxtaposed with the serious academic content could suggest a tension between the informal approach of the speaker and the formal nature of the subject matter. This difference might reflect an attempt to make complex subjects more accessible while acknowledging the weight of the academic discussion.\n",
      "\n",
      "In summary, the text reveals relational patterns centered around trust among speakers and scholars, formal authority structures based on academic recognition, and hidden conflicts potentially arising from differing interpretations within the scholarly community.\n",
      "------------------------------------------------------------\n",
      "Post 53:     J.N. Darby was one of the founders of the \"Plymouth Brethren\" and an early s...\n",
      "LLM Analysis:\n",
      "Sure! Here's an analysis of the provided text for relational patterns, identifying trust relations, formal authority structures, and hidden conflicts or tensions:\n",
      "\n",
      "### 1. Trust Relations\n",
      "- **J.N. Darby and F.F. Bruce**: The relationship here indicates a level of trust, as F.F. Bruce \"highly approved\" of Darby's translation. This approval suggests that Bruce trusted Darby‚Äôs capabilities and judgment as a translator, potentially reflecting a mutual respect in their scholarly or theological endeavors.\n",
      "- **Darby‚Äôs Work**: The mention of Darby's translation being recognized and approved further implies a trust in his theological insights and linguistic skills, which may extend to the broader community of \"Plymouth Brethren\" who look to him as a foundational figure.\n",
      "\n",
      "### 2. Formal Authority Structures\n",
      "- **Founders and Supporters**: J.N. Darby is described as one of the founders of the \"Plymouth Brethren,\" indicating a formal authority structure where he holds a significant role in the establishment of this group. His foundational status means that he likely holds influence over the beliefs and practices within this community.\n",
      "- **Translation Authority**: The text mentions Darby‚Äôs role in translating the Bible, a task that often carries formal authority in religious contexts. His translations may be considered authoritative within the \"Plymouth Brethren\" and among those who adhere to dispensationalism, creating a hierarchy of textual authority.\n",
      "- **F.F. Bruce‚Äôs Acknowledgment**: As someone who approved of Darby's translation, Bruce likely occupies a position of authority in scholarly circles, suggesting that there is a formal recognition of expertise and influence between the two figures.\n",
      "\n",
      "### 3. Hidden Conflicts or Tensions\n",
      "- **Dispensationalism Debate**: While not explicitly stated, the mention of dispensationalism can hint at underlying tensions, as this theological perspective has historically faced criticism and differing opinions among various Christian groups. There may be divisions or conflicts between those who support dispensationalism (like Darby) and those who oppose or challenge it.\n",
      "- **Translation Standards**: The reference to Darby‚Äôs translation and the mention of Young's Concordance (another significant work) may imply tensions regarding the standards and interpretations of biblical texts. If there are differing views on translation methodologies or theological interpretations between Darby and others, this could point to hidden conflicts within the broader community or among scholars.\n",
      "- **Community Dynamics**: The fact that Darby is a founder suggests that there might be factions within the Plymouth Brethren or disagreements about his teachings or translations, but the text does not delve into those details.\n",
      "\n",
      "In summary, the text reveals trust relations between key figures, formal authority structures related to theological foundations and translation, as well as potential hidden conflicts relating to theological differences and interpretations.\n",
      "------------------------------------------------------------\n",
      "Post 70:  I missed the presentations given in the morning session (when Shea gave his \"ra...\n",
      "LLM Analysis:\n",
      "To analyze the provided text for relational patterns, we can break down the elements as follows:\n",
      "\n",
      "### 1. Trust Relations\n",
      "- **Shea's Presentation**: The description of Shea's presentation as \"rambling and almost inaudible\" indicates a lack of trust or confidence in his communication skills. This could suggest that either the speaker or the audience did not find Shea's presentation effective, which may lead to a diminished trust in his expertise or authority on the subject matter.\n",
      "- **Attendee's Perspective**: The speaker's attendance at the afternoon session implies a level of trust in the relevance or quality of the presentations given later. This may indicate a preference for or trust in the other speakers over Shea.\n",
      "\n",
      "### 2. Formal Authority Structures\n",
      "- **Speaker and Panel Members**: The text mentions a speaker who was \"wired with a mike\" and panel members who had microphones at the table. This suggests a formal structure where the speaker is in a position of authority, leading the discussion, while the panel members likely have a supportive or supplementary role. The use of microphones indicates a planned and organized setting where authority is clearly delineated.\n",
      "- **Session Structure**: The distinction between the morning and afternoon sessions suggests a structured agenda, with different speakers likely assigned specific roles or topics. This structure implies an established hierarchy regarding who is leading the discussion and who is contributing.\n",
      "\n",
      "### 3. Hidden Conflicts or Tensions\n",
      "- **Criticism of Shea**: The phrase \"rambling and almost inaudible\" conveys a negative perception of Shea's presentation. This criticism may hint at underlying tensions either between the audience and Shea or among the panel members regarding the quality of his contributions, suggesting that his performance may have been a source of conflict.\n",
      "- **Missing the Morning Session**: The speaker‚Äôs choice to miss the morning session could indicate a lack of interest or disengagement from Shea's presentation, which might reflect broader tensions about the quality of presentations in the meeting. If other attendees shared this sentiment, it could lead to divisions in opinions about the effectiveness of the meeting or the speakers involved.\n",
      "\n",
      "In summary, the text reveals a relational landscape characterized by trust issues regarding Shea's effectiveness, a formal authority structure evident in the roles of speakers and panel members, and potential hidden conflicts stemming from criticism and disengagement.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Phase 2 complete: LLM has identified patterns in newsgroups data.\n"
     ]
    }
   ],
   "source": [
    "print(\"PHASE 2: LLM-ASSISTED SCALING (Newsgroups)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Analyze sample using LLM\n",
    "for idx, row in sample_interactions.iterrows():\n",
    "    text = row['text']\n",
    "    analysis = get_label(\"openai\", text, lambda t: query_openai_design(t, \"sequential\"), \"sequential_newsgroups\")\n",
    "    print(f\"Post {idx}: {text[:80]}...\")\n",
    "    print(f\"LLM Analysis:\\n{analysis}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\nPhase 2 complete: LLM has identified patterns in newsgroups data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Design on Newsgroups: Human vs LLM Analysis\n",
    "\n",
    "Compare independent human interpretation with LLM analysis on the same newsgroups sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARALLEL DESIGN: HUMAN vs LLM (Newsgroups)\n",
      "============================================================\n",
      "\n",
      "HUMAN INTERPRETATION:\n",
      "- Posts show collaborative discussion\n",
      "- Mix of technical and social content\n",
      "- Varying levels of formality and expertise\n",
      "\n",
      "LLM ANALYSIS:\n",
      "In the provided text, the roles and relationships of the actors can be inferred, even though the details are limited. Here's an analysis focusing on their positions, responsibilities, and interpersonal dynamics:\n",
      "\n",
      "1. **J.N. Darby**:\n",
      "   - **Position**: Historical figure; founder of the Plymouth Brethren movement.\n",
      "   - **Responsibilities**: As a founder, Darby played a crucial role in establishing the beliefs and practices of the Plymouth Brethren. His contributions to theological discourse, particularly in dispensationalism, would position him as an influential leader and teacher within this religious community.\n",
      "   - **Interpersonal Dynamics**: Although not directly mentioned in current relationships, his legacy likely impacts the dynamics among contemporary members of the Plymouth Brethren. His teachings may shape discussions and influence the beliefs of followers, such as those mentioned later in the text.\n",
      "\n",
      "2. **Shea**:\n",
      "   - **Position**: Presenter or speaker during the morning session.\n",
      "   - **Responsibilities**: Shea is responsible for delivering a presentation, which is implied to have been significant enough to be remembered and referenced later.\n",
      "   - **Interpersonal Dynamics**: The mention of Shea's presentation as \"rambling and almost incoherent\" suggests that his relationship with the audience (or at least the narrator) is critical. This critique implies a level of expectation from the audience and potentially a hierarchy where the presenter is accountable for engaging the attendees effectively.\n",
      "\n",
      "3. **Robinson & Robi**:\n",
      "   - **Position**: Co-authors or contributors to \"Christ's Eternal Gospel.\"\n",
      "   - **Responsibilities**: Their role involves collaborating on the text, likely sharing theological insights or interpretations related to the Plymouth Brethren or broader Christian teachings.\n",
      "   - **Interpersonal Dynamics**: The use of \"Robinson & Robi\" indicates a partnership that may reflect a collaborative relationship, suggesting shared responsibilities and a mutual commitment to the subject matter. Their joint authorship may imply a deep level of trust and teamwork, as well as a shared vision for the content they are producing.\n",
      "\n",
      "4. **Audience (Boys & Girls)**:\n",
      "   - **Position**: Members of the audience or participants in the session.\n",
      "   - **Responsibilities**: Their role is primarily to listen and engage with the material presented, contributing to the overall atmosphere of the session.\n",
      "   - **Interpersonal Dynamics**: The informal address (\"Ok boys & girls\") shows a familiar and possibly relaxed relationship between the speakers and the audience. It indicates an attempt to create a welcoming environment, suggesting that the speakers see the audience as equals or peers in the exploration of spiritual topics.\n",
      "\n",
      "In summary, the actors in this text interact within a framework of hierarchical and collaborative relationships. J.N. Darby's historical influence shapes the context, while Shea's presentation serves as a focal point for critique. Robinson and Robi's partnership reflects collaboration, and the audience's engagement highlights a communal dynamic in the exploration of faith-related discussions.\n",
      "\n",
      "Convergences and divergences between human and LLM are analytic resources.\n"
     ]
    }
   ],
   "source": [
    "print(\"PARALLEL DESIGN: HUMAN vs LLM (Newsgroups)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "print(\"HUMAN INTERPRETATION:\")\n",
    "print(\"- Posts show collaborative discussion\")\n",
    "print(\"- Mix of technical and social content\")\n",
    "print(\"- Varying levels of formality and expertise\")\n",
    "print()\n",
    "\n",
    "print(\"LLM ANALYSIS:\")\n",
    "corpus_text = \"\\n\".join([row['text'][:100] for _, row in sample_interactions.iterrows()])\n",
    "llm_ng_analysis = get_label(\"openai\", corpus_text, query_openai_roles, \"parallel_newsgroups\")\n",
    "print(llm_ng_analysis)\n",
    "print()\n",
    "print(\"Convergences and divergences between human and LLM are analytic resources.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymization and Audit Trail for Newsgroups\n",
    "\n",
    "Apply ethical safeguards and maintain audit trail for newsgroups analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANONYMIZATION (Newsgroups):\n",
      "          source anon_source         target anon_target\n",
      "0  Researcher_15    5264903f  Researcher_12    30f11a4b\n",
      "1  Researcher_05    5c4c51f2  Researcher_11    002f27a4\n",
      "2  Researcher_02    b4c254e8  Researcher_00    fa949140\n",
      "3  Researcher_11    002f27a4  Researcher_00    fa949140\n",
      "4  Researcher_09    8e63bbe2  Researcher_01    1cf82af9\n",
      "\n",
      "Anonymization preserves network structure while protecting participant identity.\n"
     ]
    }
   ],
   "source": [
    "# Anonymize newsgroups researchers\n",
    "interactions['anon_source'] = interactions['source'].apply(anonymize_user)\n",
    "interactions['anon_target'] = interactions['target'].apply(anonymize_user)\n",
    "\n",
    "print(\"ANONYMIZATION (Newsgroups):\")\n",
    "print(interactions[['source', 'anon_source', 'target', 'anon_target']].head())\n",
    "print()\n",
    "print(\"Anonymization preserves network structure while protecting participant identity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Construction from Newsgroups\n",
    "\n",
    "Build a directed graph from the newsgroups interactions using anonymized identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Statistics:\n",
      "Nodes: 20\n",
      "Edges: 86\n",
      "Density: 0.226\n",
      "\n",
      "Sample edges (anonymized):\n",
      "('5264903f', '30f11a4b', {})\n",
      "('5264903f', '5f69b4a7', {})\n",
      "('5264903f', '5c4c51f2', {})\n",
      "('30f11a4b', 'aae702ef', {})\n",
      "('30f11a4b', '1cf82af9', {})\n",
      "('30f11a4b', 'fa949140', {})\n",
      "('30f11a4b', '39119a69', {})\n",
      "('30f11a4b', '002f27a4', {})\n",
      "('30f11a4b', '01664e66', {})\n",
      "('5c4c51f2', '002f27a4', {})\n"
     ]
    }
   ],
   "source": [
    "# Build the Graph from anonymized interactions\n",
    "G = nx.from_pandas_edgelist(interactions, 'anon_source', 'anon_target', \n",
    "                            create_using=nx.DiGraph())\n",
    "\n",
    "print(f\"Graph Statistics:\")\n",
    "print(f\"Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Edges: {G.number_of_edges()}\")\n",
    "print(f\"Density: {nx.density(G):.3f}\")\n",
    "print()\n",
    "\n",
    "# Print first 10 edges\n",
    "print(\"Sample edges (anonymized):\")\n",
    "for i, e in enumerate(G.edges(data=True)):\n",
    "    if i < 10:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Visualization\n",
    "\n",
    "Visualize the newsgroups social network using pyvis with labels only (no circles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"550px\"\n",
       "            src=\"newsgroups_graph_s4.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13ddb8eb0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Network\n",
    "net = Network(height=\"500px\", width=\"100%\", directed=True, bgcolor=\"#ffffff\")\n",
    "\n",
    "# Add Nodes (labels only, no visible circles)\n",
    "for node in G.nodes():\n",
    "    net.add_node(\n",
    "        node, \n",
    "        label=node, \n",
    "        shape='dot',\n",
    "        size=1,\n",
    "        color='#ffffff',\n",
    "        borderWidth=0,\n",
    "        font={'size': 12, 'color': 'black', 'align': 'center'}\n",
    "    )\n",
    "    \n",
    "# Add Edges\n",
    "for source, target in G.edges():\n",
    "    net.add_edge(\n",
    "        source, \n",
    "        target, \n",
    "        color='#848484',\n",
    "        arrows={'to': {'enabled': True, 'scaleFactor': 0.5}},\n",
    "        smooth={'type': 'curvedCW', 'roundness': 0.2},\n",
    "        font={'align': 'top', 'size': 12, 'color': 'blue'}\n",
    "    )\n",
    "\n",
    "# Physics and Rendering\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": { \"gravitationalConstant\": -3000, \"springLength\": 150 }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "html_content = net.generate_html()\n",
    "with open(\"newsgroups_graph_s4.html\", \"w\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "IPython.display.IFrame(src=\"newsgroups_graph_s4.html\", width='100%', height='550px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
