{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">Â© 2026 Moses Boudourides. All Rights Reserved.</div>\n",
    "\n",
    "# LLMs for Qualitative and Mixed-Methods Social Network Analysis (SNA)\n",
    "## Moses Boudourides\n",
    "\n",
    "# Session 5: Computational Practice and Ethical Responsibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import hashlib\n",
    "import random\n",
    "import re\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import IPython\n",
    "from openai import OpenAI\n",
    "# import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. & 2. KEY LOADING & INITIALIZATION ---\n",
    "\n",
    "# Force Google to use REST to avoid ALTS/GCP credential errors\n",
    "os.environ[\"GOOGLE_API_USE_MTLS\"] = \"never\" \n",
    "\n",
    "def get_api_key(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return f.read().strip().replace('\"', '').replace(\"'\", \"\")\n",
    "    return None\n",
    "\n",
    "oa_key = get_api_key(\"openai_key.txt\")\n",
    "# gem_key = get_api_key(\"gemini_key.txt\")\n",
    "\n",
    "# Initialize OpenAI\n",
    "client_oa = OpenAI(api_key=oa_key)\n",
    "\n",
    "# # Initialize Gemini using 'rest' transport to bypass gRPC/ALTS errors\n",
    "# genai.configure(api_key=gem_key, transport='rest')\n",
    "\n",
    "# # Dynamic Model Selection\n",
    "# available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
    "# target_model = 'gemini-1.5-flash' if 'models/gemini-1.5-flash' in available_models else available_models[0].split('/')[-1]\n",
    "# model_gemini = genai.GenerativeModel(target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Computational Practice and Ethical Responsibility\n",
    "\n",
    "**Goal:**  \n",
    "Demonstrate an end-to-end LLM-augmented qualitative SNA workflow with explicit ethical checkpoints.\n",
    "\n",
    "**Important Note:** This notebook is illustrative. Any real-world application requires ethics approval (where applicable), informed consent, and careful consideration of harm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I depend on Leah for confidential advice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marcus officially manages the team but avoids ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leah and Marcus cooperate publicly but mistrus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tina feels excluded from informal decision-mak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0          I depend on Leah for confidential advice.\n",
       "1  Marcus officially manages the team but avoids ...\n",
       "2  Leah and Marcus cooperate publicly but mistrus...\n",
       "3  Tina feels excluded from informal decision-mak..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. DATA & PERSISTENT QUERY STEP ---\n",
    "\n",
    "# 2. Persistence Logic\n",
    "CACHE_FILE = \"llm_cache_s5.json\"\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"r\") as f:\n",
    "        cache = json.load(f)\n",
    "else:\n",
    "    cache = {}\n",
    "\n",
    "def get_label(model_id, text, api_func, prompt_type=\"practice\"):\n",
    "    # Unique key ensures cache stays valid even if prompt or text changes\n",
    "    cache_key = f\"{model_id}_{prompt_type}_{text[:50]}\"\n",
    "    \n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    # Cache Miss: Call API\n",
    "    result = api_func(text)\n",
    "    cache[cache_key] = result\n",
    "    \n",
    "    # Save updated cache to disk\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump(cache, f)\n",
    "    return result\n",
    "\n",
    "# 3. API Execution Wrappers\n",
    "def query_openai_relationships(text):\n",
    "    prompt = f\"\"\"Identify social relationships described in the following text.\n",
    "Return actor pairs and a brief description of the relationship.\n",
    "\n",
    "Text: {text}\"\"\"\n",
    "    res = client_oa.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return res.choices[0].message.content.strip()\n",
    "\n",
    "# Simulated relational text data (synthetic to avoid ethical violations)\n",
    "texts_small = [\n",
    "    \"I depend on Leah for confidential advice.\",\n",
    "    \"Marcus officially manages the team but avoids conflict.\",\n",
    "    \"Leah and Marcus cooperate publicly but mistrust each other privately.\",\n",
    "    \"Tina feels excluded from informal decision-making.\"\n",
    "]\n",
    "\n",
    "df_small = pd.DataFrame({\"text\": texts_small})\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Cleaning\n",
    "\n",
    "Real-world text data is messy. Preprocessing is a crucial first step before any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING RESULTS:\n",
      "\n",
      "Text 1:\n",
      "  Original: 'I depend on Leah for confidential advice.'\n",
      "  Cleaned:  'I depend on Leah for confidential advice.'\n",
      "\n",
      "Text 2:\n",
      "  Original: 'Marcus officially manages the team but avoids conflict.'\n",
      "  Cleaned:  'Marcus officially manages the team but avoids conflict.'\n",
      "\n",
      "Text 3:\n",
      "  Original: 'Leah and Marcus cooperate publicly but mistrust each other privately.'\n",
      "  Cleaned:  'Leah and Marcus cooperate publicly but mistrust each other privately.'\n",
      "\n",
      "Text 4:\n",
      "  Original: 'Tina feels excluded from informal decision-making.'\n",
      "  Cleaned:  'Tina feels excluded from informal decision-making.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Strip whitespace\n",
    "    cleaned = text.strip()\n",
    "    # Remove extra whitespace\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned)\n",
    "    return cleaned\n",
    "\n",
    "df_small['cleaned_text'] = df_small['text'].apply(preprocess_text)\n",
    "\n",
    "print(\"PREPROCESSING RESULTS:\")\n",
    "print()\n",
    "for i, (orig, clean) in enumerate(zip(df_small['text'], df_small['cleaned_text'])):\n",
    "    print(f\"Text {i+1}:\")\n",
    "    print(f\"  Original: {repr(orig)}\")\n",
    "    print(f\"  Cleaned:  {repr(clean)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethical Checkpoint 1: Data Source\n",
    "\n",
    "Before analysis, ask:\n",
    "- Who produced these texts?\n",
    "- Did they consent to analysis?\n",
    "- Who is implicated indirectly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETHICAL CHECKPOINT 1: DATA SOURCE\n",
      "============================================================\n",
      "\n",
      "Critical Questions:\n",
      "1. Who produced these texts?\n",
      "   - In this example: Synthetic data (no real people)\n",
      "\n",
      "2. Did they consent to analysis?\n",
      "   - In this example: N/A (synthetic)\n",
      "   - In real research: Informed consent is essential\n",
      "\n",
      "3. Who is implicated indirectly?\n",
      "   - In this example: Fictional actors (Leah, Marcus, Tina)\n",
      "   - In real research: Consider all affected parties\n",
      "\n",
      "Proceeding with synthetic data for illustration purposes.\n"
     ]
    }
   ],
   "source": [
    "print(\"ETHICAL CHECKPOINT 1: DATA SOURCE\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Critical Questions:\")\n",
    "print(\"1. Who produced these texts?\")\n",
    "print(\"   - In this example: Synthetic data (no real people)\")\n",
    "print()\n",
    "print(\"2. Did they consent to analysis?\")\n",
    "print(\"   - In this example: N/A (synthetic)\")\n",
    "print(\"   - In real research: Informed consent is essential\")\n",
    "print()\n",
    "print(\"3. Who is implicated indirectly?\")\n",
    "print(\"   - In this example: Fictional actors (Leah, Marcus, Tina)\")\n",
    "print(\"   - In real research: Consider all affected parties\")\n",
    "print()\n",
    "print(\"Proceeding with synthetic data for illustration purposes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-Assisted Interpretation (Provisional)\n",
    "\n",
    "LLM outputs are suggestions, not facts. They require researcher interpretation and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-ASSISTED INTERPRETATION\n",
      "============================================================\n",
      "\n",
      "Text 1: I depend on Leah for confidential advice.\n",
      "LLM Interpretation:\n",
      "1. **Actor Pair**: \"I\" and \"Leah\"  \n",
      "   **Relationship Description**: The speaker relies on Leah for confidential advice, indicating a relationship of trust and dependency.\n",
      "------------------------------------------------------------\n",
      "Text 2: Marcus officially manages the team but avoids conflict.\n",
      "LLM Interpretation:\n",
      "1. **Marcus - Team**: Marcus is the manager of the team, indicating a hierarchical relationship where he holds authority over the team members. However, he tends to avoid conflict, suggesting a possibly passive or non-confrontational approach to his leadership role.\n",
      "\n",
      "2. **Marcus - Conflict**: Although not a direct relationship with another actor, Marcus has a relationship with conflict, which he avoids. This indicates a personal characteristic or behavior trait that impacts his management style and interactions with the team.\n",
      "------------------------------------------------------------\n",
      "Text 3: Leah and Marcus cooperate publicly but mistrust each other privately.\n",
      "LLM Interpretation:\n",
      "1. **Leah and Marcus**: They have a public cooperation relationship, suggesting they work together or support each other in front of others. However, there is an underlying mistrust between them when they are not in public, indicating a lack of confidence or faith in each other's intentions or reliability.\n",
      "------------------------------------------------------------\n",
      "Text 4: Tina feels excluded from informal decision-making.\n",
      "LLM Interpretation:\n",
      "1. **Tina - Informal Decision-Makers**: Tina feels excluded from the group of individuals involved in informal decision-making. This suggests a relationship where Tina is on the outside of a social circle or group that makes decisions without her input.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"LLM-ASSISTED INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "for i, text in enumerate(texts_small):\n",
    "    interpretation = get_label(\"openai\", text, query_openai_relationships, \"relationships\")\n",
    "    print(f\"Text {i+1}: {text}\")\n",
    "    print(f\"LLM Interpretation:\\n{interpretation}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethical Checkpoint 2: Hallucination Risk\n",
    "\n",
    "Ask:\n",
    "- Are relationships inferred or stated?\n",
    "- Are motives attributed without evidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETHICAL CHECKPOINT 2: HALLUCINATION RISK\n",
      "============================================================\n",
      "\n",
      "Critical Questions:\n",
      "1. Are relationships inferred or stated?\n",
      "   - Check: Does the LLM output match the original text?\n",
      "   - Risk: LLM may infer relationships not explicitly stated\n",
      "\n",
      "2. Are motives attributed without evidence?\n",
      "   - Check: Are psychological states inferred?\n",
      "   - Risk: LLM may hallucinate internal states or intentions\n",
      "\n",
      "Mitigation: Retain only relationships explicitly stated in text.\n"
     ]
    }
   ],
   "source": [
    "print(\"ETHICAL CHECKPOINT 2: HALLUCINATION RISK\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Critical Questions:\")\n",
    "print(\"1. Are relationships inferred or stated?\")\n",
    "print(\"   - Check: Does the LLM output match the original text?\")\n",
    "print(\"   - Risk: LLM may infer relationships not explicitly stated\")\n",
    "print()\n",
    "print(\"2. Are motives attributed without evidence?\")\n",
    "print(\"   - Check: Are psychological states inferred?\")\n",
    "print(\"   - Risk: LLM may hallucinate internal states or intentions\")\n",
    "print()\n",
    "print(\"Mitigation: Retain only relationships explicitly stated in text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Researcher Filtering\n",
    "\n",
    "We retain only relationships explicitly stated in text, filtering out inferred or hallucinated content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERED NETWORK (Explicit Relationships Only):\n",
      "\n",
      "Nodes: ['Narrator', 'Leah', 'Marcus', 'Tina', 'Group']\n",
      "Edges: [('Narrator', 'Leah'), ('Narrator', 'Marcus'), ('Leah', 'Marcus'), ('Tina', 'Group')]\n",
      "\n",
      "  Narrator -- Leah: confidential trust\n",
      "  Narrator -- Marcus: formal authority\n",
      "  Leah -- Marcus: ambivalent cooperation\n",
      "  Tina -- Group: exclusion\n"
     ]
    }
   ],
   "source": [
    "# Build network with explicit relationships only\n",
    "edges = [\n",
    "    (\"Narrator\", \"Leah\", {\"meaning\": \"confidential trust\", \"explicit\": True}),\n",
    "    (\"Narrator\", \"Marcus\", {\"meaning\": \"formal authority\", \"explicit\": True}),\n",
    "    (\"Leah\", \"Marcus\", {\"meaning\": \"ambivalent cooperation\", \"explicit\": True}),\n",
    "    (\"Tina\", \"Group\", {\"meaning\": \"exclusion\", \"explicit\": True})\n",
    "]\n",
    "\n",
    "G_filtered = nx.Graph()\n",
    "for u, v, attr in edges:\n",
    "    G_filtered.add_edge(u, v, **attr)\n",
    "\n",
    "print(\"FILTERED NETWORK (Explicit Relationships Only):\")\n",
    "print()\n",
    "print(f\"Nodes: {list(G_filtered.nodes())}\")\n",
    "print(f\"Edges: {list(G_filtered.edges())}\")\n",
    "print()\n",
    "for u, v, d in G_filtered.edges(data=True):\n",
    "    print(f\"  {u} -- {v}: {d['meaning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethical Checkpoint 3: Representation\n",
    "\n",
    "Ask:\n",
    "- Does this visualization stigmatize?\n",
    "- Could it harm participants if disclosed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETHICAL CHECKPOINT 3: REPRESENTATION\n",
      "============================================================\n",
      "\n",
      "Critical Questions:\n",
      "1. Does this visualization stigmatize?\n",
      "   - Consider: How are actors positioned?\n",
      "   - Consider: Does the network reinforce stereotypes?\n",
      "\n",
      "2. Could it harm participants if disclosed?\n",
      "   - Consider: Could re-identification occur?\n",
      "   - Consider: Could relationships damage careers or relationships?\n",
      "\n",
      "Mitigation: Use anonymization and careful disclosure strategies.\n"
     ]
    }
   ],
   "source": [
    "print(\"ETHICAL CHECKPOINT 3: REPRESENTATION\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Critical Questions:\")\n",
    "print(\"1. Does this visualization stigmatize?\")\n",
    "print(\"   - Consider: How are actors positioned?\")\n",
    "print(\"   - Consider: Does the network reinforce stereotypes?\")\n",
    "print()\n",
    "print(\"2. Could it harm participants if disclosed?\")\n",
    "print(\"   - Consider: Could re-identification occur?\")\n",
    "print(\"   - Consider: Could relationships damage careers or relationships?\")\n",
    "print()\n",
    "print(\"Mitigation: Use anonymization and careful disclosure strategies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Anonymization and Ethical Implementation\n",
    "\n",
    "Protect participant identity while maintaining network structure using hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANONYMIZATION:\n",
      "\n",
      "Original User Mapping:\n",
      "     user anon_user\n",
      "0    Leah  1373cf56\n",
      "1  Marcus  245536ac\n",
      "2    Tina  0fd1eb2e\n",
      "\n",
      "Anonymization preserves network structure while protecting identity.\n"
     ]
    }
   ],
   "source": [
    "# Anonymization function\n",
    "def anonymize_user(username):\n",
    "    return hashlib.sha256(username.encode()).hexdigest()[:8]\n",
    "\n",
    "# Simulated raw data\n",
    "raw_data = [\n",
    "    {\"user\": \"Leah\", \"text\": \"I provide confidential advice.\", \"timestamp\": \"2023-10-01\"},\n",
    "    {\"user\": \"Marcus\", \"text\": \"I manage the team formally.\", \"timestamp\": \"2023-10-02\"},\n",
    "    {\"user\": \"Tina\", \"text\": \"I feel excluded from decisions.\", \"timestamp\": \"2023-10-03\"}\n",
    "]\n",
    "\n",
    "df_raw = pd.DataFrame(raw_data)\n",
    "\n",
    "# Clean and anonymize\n",
    "df_raw['clean_text'] = df_raw['text'].str.lower()\n",
    "df_raw['anon_user'] = df_raw['user'].apply(anonymize_user)\n",
    "\n",
    "print(\"ANONYMIZATION:\")\n",
    "print()\n",
    "print(\"Original User Mapping:\")\n",
    "print(df_raw[['user', 'anon_user']])\n",
    "print()\n",
    "print(\"Anonymization preserves network structure while protecting identity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Inter-Rater Reliability\n",
    "\n",
    "It is essential to validate LLM output against human coding to ensure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION AND INTER-RATER RELIABILITY\n",
      "============================================================\n",
      "\n",
      "LLM Output:        [('Leah', 'Narrator'), ('Marcus', 'Narrator'), ('Leah', 'Marcus'), ('Tina', 'Group')]\n",
      "Human Coder:       [('Leah', 'Narrator'), ('Marcus', 'Narrator'), ('Leah', 'Marcus'), ('Tina', 'Group')]\n",
      "\n",
      "Agreement:         4/4 pairs\n",
      "Accuracy:          100%\n",
      "\n",
      "Note: High agreement suggests reliable extraction, but always validate.\n"
     ]
    }
   ],
   "source": [
    "# Simulated LLM output vs. Human coder output\n",
    "llm_output = [(\"Leah\", \"Narrator\"), (\"Marcus\", \"Narrator\"), (\"Leah\", \"Marcus\"), (\"Tina\", \"Group\")]\n",
    "human_coder_output = [(\"Leah\", \"Narrator\"), (\"Marcus\", \"Narrator\"), (\"Leah\", \"Marcus\"), (\"Tina\", \"Group\")]\n",
    "\n",
    "# Calculate agreement\n",
    "agreement = sum(1 for x, y in zip(llm_output, human_coder_output) if x == y)\n",
    "accuracy = agreement / len(llm_output)\n",
    "\n",
    "print(\"VALIDATION AND INTER-RATER RELIABILITY\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"LLM Output:        {llm_output}\")\n",
    "print(f\"Human Coder:       {human_coder_output}\")\n",
    "print()\n",
    "print(f\"Agreement:         {agreement}/{len(llm_output)} pairs\")\n",
    "print(f\"Accuracy:          {accuracy:.0%}\")\n",
    "print()\n",
    "print(\"Note: High agreement suggests reliable extraction, but always validate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation and Audit Trail\n",
    "\n",
    "Document all LLM use for transparency and accountability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCUMENTATION AND AUDIT TRAIL:\n",
      "\n",
      "         model                              purpose                           filters                       review        date\n",
      "0  gpt-4o-mini  Provisional relationship extraction  Only explicit relations retained  Manual verification applied  2026-01-26\n",
      "\n",
      "This documentation is part of ethical accountability.\n"
     ]
    }
   ],
   "source": [
    "# Minimal documentation record\n",
    "documentation = pd.DataFrame([\n",
    "    {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"purpose\": \"Provisional relationship extraction\",\n",
    "        \"filters\": \"Only explicit relations retained\",\n",
    "        \"review\": \"Manual verification applied\",\n",
    "        \"date\": \"2026-01-26\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"DOCUMENTATION AND AUDIT TRAIL:\")\n",
    "print()\n",
    "print(documentation.to_string())\n",
    "print()\n",
    "print(\"This documentation is part of ethical accountability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 5 Takeaway\n",
    "\n",
    "Ethical responsibility is not an add-on. It is embedded in:\n",
    "- Data choices\n",
    "- Prompts\n",
    "- Filters\n",
    "- Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Applying Computational Practice to 20 Newsgroups Dataset\n",
    "\n",
    "Now we apply the same ethical and computational practices to a larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ SNAPSHOT NOT FOUND. GENERATING NEW SAMPLE...\n",
      "ðŸ’¾ PERMANENTLY SAVED: news_snapshot_m100_514f6311.csv\n",
      "\n",
      "--- READY: 100 interactions between 20 nodes ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Researcher_09</td>\n",
       "      <td>Researcher_11</td>\n",
       "      <td>In case you missed it on the news....the first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Researcher_17</td>\n",
       "      <td>Researcher_04</td>\n",
       "      <td>We have no way of knowing because we cann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Researcher_15</td>\n",
       "      <td>Researcher_14</td>\n",
       "      <td>The lengthy article you quote doesn't imply ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Researcher_09</td>\n",
       "      <td>Researcher_07</td>\n",
       "      <td>The recent rise of nostalgia in this group, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Researcher_17</td>\n",
       "      <td>Researcher_08</td>\n",
       "      <td># ## Absolutely nothing, seeing as there is no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source         target  \\\n",
       "0  Researcher_09  Researcher_11   \n",
       "1  Researcher_17  Researcher_04   \n",
       "2  Researcher_15  Researcher_14   \n",
       "3  Researcher_09  Researcher_07   \n",
       "4  Researcher_17  Researcher_08   \n",
       "\n",
       "                                                text  \n",
       "0  In case you missed it on the news....the first...  \n",
       "1       We have no way of knowing because we cann...  \n",
       "2    The lengthy article you quote doesn't imply ...  \n",
       "3  The recent rise of nostalgia in this group, co...  \n",
       "4  # ## Absolutely nothing, seeing as there is no...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "n = 20  # Number of Nodes (Researchers)\n",
    "m = 100  # Number of Edges (Interactions/posts)\n",
    "\n",
    "# Dataset Description\n",
    "# The 20 Newsgroups dataset is a collection of approximately 18,000 newsgroup posts \n",
    "# that originated in the early days of the internet (Usenet) and they can be \n",
    "# displayed as a social network (a directed weighted multigraph) among thousands \n",
    "# of unique nodes/researchers interacting/replying in the posts of the 20 newsgroups.\n",
    "# Taken from sklearn.datasets.fetch_20newsgroups\n",
    "\n",
    "# Generate a unique filename based on m to avoid mixing samples\n",
    "config_hash = hashlib.md5(f\"{m}_newsgroups_s5\".encode()).hexdigest()[:8]\n",
    "SNAPSHOT_FILE = f\"news_snapshot_m{m}_{config_hash}.csv\"\n",
    "\n",
    "# CHECK IF WE ALREADY HAVE THE COMPLETE DATA\n",
    "if os.path.exists(SNAPSHOT_FILE):\n",
    "    print(f\"âœ… LOADING PERMANENT SNAPSHOT: {SNAPSHOT_FILE}\")\n",
    "    interactions = pd.read_csv(SNAPSHOT_FILE)\n",
    "else:\n",
    "    print(f\"ðŸš€ SNAPSHOT NOT FOUND. GENERATING NEW SAMPLE...\")\n",
    "    \n",
    "    # 1. Fetch the big dataset (11,000+ posts)\n",
    "    newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "    full_df = pd.DataFrame({'text': newsgroups.data})\n",
    "    \n",
    "    # 2. Filter and Sample M posts\n",
    "    df = full_df[full_df['text'].str.strip().str.len() > 20].copy()\n",
    "    subset = df.sample(n=m, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # 3. Assign the Social Structure (Source/Target)\n",
    "    user_pool = [f\"Researcher_{i:02d}\" for i in range(n)]\n",
    "    sources = [random.choice(user_pool) for _ in range(m)]\n",
    "    targets = [random.choice([u for u in user_pool if u != s]) for s in sources]\n",
    "\n",
    "    interactions = pd.DataFrame({\n",
    "        \"source\": sources,\n",
    "        \"target\": targets,\n",
    "        \"text\": subset['text'].str[:300].replace('\\n', ' ', regex=True)\n",
    "    })\n",
    "\n",
    "    # 4. IMMEDIATELY SAVE (before LLM processing)\n",
    "    interactions.to_csv(SNAPSHOT_FILE, index=False)\n",
    "    print(f\"ðŸ’¾ PERMANENTLY SAVED: {SNAPSHOT_FILE}\")\n",
    "\n",
    "print(f\"\\n--- READY: {len(interactions)} interactions between {n} nodes ---\")\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Newsgroups Data\n",
    "\n",
    "Apply the same preprocessing and cleaning procedures to the newsgroups dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING NEWSGROUPS DATA:\n",
      "\n",
      "Original text length (mean): 263.0 chars\n",
      "Cleaned text length (mean):  252.7 chars\n",
      "\n",
      "Sample (before and after):\n",
      "Before: In case you missed it on the news....the first 16 Haitians of many that tested positive for HIV and ...\n",
      "After:  In case you missed it on the news....the first 16 Haitians of many that tested positive for HIV and ...\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to newsgroups\n",
    "interactions['cleaned_text'] = interactions['text'].apply(preprocess_text)\n",
    "\n",
    "print(\"PREPROCESSING NEWSGROUPS DATA:\")\n",
    "print()\n",
    "print(f\"Original text length (mean): {interactions['text'].str.len().mean():.1f} chars\")\n",
    "print(f\"Cleaned text length (mean):  {interactions['cleaned_text'].str.len().mean():.1f} chars\")\n",
    "print()\n",
    "print(\"Sample (before and after):\")\n",
    "sample_idx = 0\n",
    "print(f\"Before: {interactions.iloc[sample_idx]['text'][:100]}...\")\n",
    "print(f\"After:  {interactions.iloc[sample_idx]['cleaned_text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-Assisted Interpretation on Newsgroups Sample\n",
    "\n",
    "Apply LLM-assisted interpretation with ethical checkpoints to newsgroups data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-ASSISTED INTERPRETATION (Newsgroups Sample):\n",
      "============================================================\n",
      "\n",
      "Post 83:     Ok boys & girls, hang on; here we go!      Christ's Eternal Gospel          ...\n",
      "Interpretation:\n",
      "Based on the text provided, the social relationships can be identified as follows:\n",
      "\n",
      "1. **Robinson & Robinson**\n",
      "   - **Relationship**: Collaborative Partnership\n",
      "   - **Description**: This pair appears to be working together on a topic related to the field of religious studies, possibly co-authors or collaborators on a project or publication.\n",
      "\n",
      "2. **WS LaSor & RH Eisenman**\n",
      "   - **Relationship**: Academic Peers\n",
      "   - **Description**: Both individuals are mentioned in the context of religious texts and scholarly analysis, indicating they are likely colleagues or peers in the academic field, possibly engaging in scholarly discourse or research.\n",
      "\n",
      "3. **RH Eisenman & Quamran**\n",
      "   - **Relationship**: Researcher and Subject of Study\n",
      "   - **Description**: RH Eisenman is associated with the Dead Sea Scrolls, which are linked to the site of Qumran, suggesting a researcher-subject relationship where Eisenman studies or analyzes the historical and religious significance of Qumran in relation to the Dead Sea Scrolls.\n",
      "\n",
      "4. **RH Eisenman & Dead Sea Scrolls Uncovered**\n",
      "   - **Relationship**: Author and Work/Publication\n",
      "   - **Description**: RH Eisenman is likely the author of a work titled \"Dead Sea Scrolls Uncovered,\" establishing a clear author-publication relationship.\n",
      "------------------------------------------------------------\n",
      "Post 53:     J.N. Darby was one of the founders of the \"Plymouth Brethren\" and an early s...\n",
      "Interpretation:\n",
      "Here are the identified social relationships based on the provided text:\n",
      "\n",
      "1. **J.N. Darby - F.F. Bruce**\n",
      "   - **Relationship Description**: Professional approval; F.F. Bruce highly approved of J.N. Darby's translation of the Bible.\n",
      "\n",
      "2. **J.N. Darby - Plymouth Brethren**\n",
      "   - **Relationship Description**: Founding relationship; J.N. Darby was one of the founders of the Plymouth Brethren.\n",
      "\n",
      "3. **J.N. Darby - Bible Translation**\n",
      "   - **Relationship Description**: Creator and contributor; J.N. Darby translated the Bible into several languages.\n",
      "\n",
      "4. **J.N. Darby - Young's Concordance**\n",
      "   - **Relationship Description**: Attribution; J.N. Darby is associated with the same individual who created Young's Concordance, indicating a professional connection in biblical scholarship.\n",
      "------------------------------------------------------------\n",
      "Post 70:  I missed the presentations given in the morning session (when Shea gave his \"ra...\n",
      "Interpretation:\n",
      "1. **Shea - Presentation Audience**\n",
      "   - Description: Shea is a speaker who presented in the morning session, though the audience missed his presentation.\n",
      "\n",
      "2. **Speaker - Panel Members**\n",
      "   - Description: The speaker is addressing the panel members during the meeting, with microphones provided for their participation. \n",
      "\n",
      "3. **Attendee - Afternoon Session**\n",
      "   - Description: The attendee who missed the morning session participated in the afternoon session, indicating a relationship of attendance and engagement with the meeting content.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample a subset for detailed analysis\n",
    "sample_size = min(3, len(interactions))\n",
    "sample_interactions = interactions.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(\"LLM-ASSISTED INTERPRETATION (Newsgroups Sample):\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "for idx, row in sample_interactions.iterrows():\n",
    "    text = row['text']\n",
    "    interpretation = get_label(\"openai\", text, query_openai_relationships, \"newsgroups_relationships\")\n",
    "    print(f\"Post {idx}: {text[:80]}...\")\n",
    "    print(f\"Interpretation:\\n{interpretation}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymization of Newsgroups Researchers\n",
    "\n",
    "Apply anonymization to protect researcher identity while preserving network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANONYMIZATION (Newsgroups):\n",
      "\n",
      "          source anon_source         target anon_target\n",
      "0  Researcher_09    8e63bbe2  Researcher_11    002f27a4\n",
      "1  Researcher_17    a1c35218  Researcher_04    12035e93\n",
      "2  Researcher_15    5264903f  Researcher_14    cdc051b2\n",
      "3  Researcher_09    8e63bbe2  Researcher_07    55c33e28\n",
      "4  Researcher_17    a1c35218  Researcher_08    03a3094f\n",
      "5  Researcher_08    03a3094f  Researcher_02    b4c254e8\n",
      "6  Researcher_11    002f27a4  Researcher_01    1cf82af9\n",
      "7  Researcher_05    5c4c51f2  Researcher_02    b4c254e8\n",
      "8  Researcher_01    1cf82af9  Researcher_06    01664e66\n",
      "9  Researcher_15    5264903f  Researcher_10    28385db5\n",
      "\n",
      "Anonymization preserves network structure while protecting identity.\n"
     ]
    }
   ],
   "source": [
    "# Anonymize newsgroups researchers\n",
    "interactions['anon_source'] = interactions['source'].apply(anonymize_user)\n",
    "interactions['anon_target'] = interactions['target'].apply(anonymize_user)\n",
    "\n",
    "print(\"ANONYMIZATION (Newsgroups):\")\n",
    "print()\n",
    "print(interactions[['source', 'anon_source', 'target', 'anon_target']].head(10))\n",
    "print()\n",
    "print(\"Anonymization preserves network structure while protecting identity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Construction from Newsgroups\n",
    "\n",
    "Build a directed graph from the anonymized newsgroups interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Statistics:\n",
      "Nodes: 20\n",
      "Edges: 81\n",
      "Density: 0.213\n",
      "\n",
      "Sample edges (anonymized):\n",
      "('8e63bbe2', '002f27a4', {})\n",
      "('8e63bbe2', '55c33e28', {})\n",
      "('8e63bbe2', '5c32df15', {})\n",
      "('8e63bbe2', '5264903f', {})\n",
      "('8e63bbe2', '12035e93', {})\n",
      "('002f27a4', '1cf82af9', {})\n",
      "('a1c35218', '12035e93', {})\n",
      "('a1c35218', '03a3094f', {})\n",
      "('a1c35218', '30f11a4b', {})\n",
      "('a1c35218', 'cdc051b2', {})\n"
     ]
    }
   ],
   "source": [
    "# Build the Graph from anonymized interactions\n",
    "G = nx.from_pandas_edgelist(interactions, 'anon_source', 'anon_target', \n",
    "                            create_using=nx.DiGraph())\n",
    "\n",
    "print(f\"Graph Statistics:\")\n",
    "print(f\"Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Edges: {G.number_of_edges()}\")\n",
    "print(f\"Density: {nx.density(G):.3f}\")\n",
    "print()\n",
    "\n",
    "# Print first 10 edges\n",
    "print(\"Sample edges (anonymized):\")\n",
    "for i, e in enumerate(G.edges(data=True)):\n",
    "    if i < 10:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Visualization\n",
    "\n",
    "Visualize the newsgroups social network using pyvis with labels only (no circles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"550px\"\n",
       "            src=\"newsgroups_graph_s5.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1432cded0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Network\n",
    "net = Network(height=\"500px\", width=\"100%\", directed=True, bgcolor=\"#ffffff\")\n",
    "\n",
    "# Add Nodes (labels only, no visible circles)\n",
    "for node in G.nodes():\n",
    "    net.add_node(\n",
    "        node, \n",
    "        label=node, \n",
    "        shape='dot',\n",
    "        size=1,\n",
    "        color='#ffffff',\n",
    "        borderWidth=0,\n",
    "        font={'size': 12, 'color': 'black', 'align': 'center'}\n",
    "    )\n",
    "    \n",
    "# Add Edges\n",
    "for source, target in G.edges():\n",
    "    net.add_edge(\n",
    "        source, \n",
    "        target, \n",
    "        color='#848484',\n",
    "        arrows={'to': {'enabled': True, 'scaleFactor': 0.5}},\n",
    "        smooth={'type': 'curvedCW', 'roundness': 0.2},\n",
    "        font={'align': 'top', 'size': 12, 'color': 'blue'}\n",
    "    )\n",
    "\n",
    "# Physics and Rendering\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": { \"gravitationalConstant\": -3000, \"springLength\": 150 }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "html_content = net.generate_html()\n",
    "with open(\"newsgroups_graph_s5.html\", \"w\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "IPython.display.IFrame(src=\"newsgroups_graph_s5.html\", width='100%', height='550px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
